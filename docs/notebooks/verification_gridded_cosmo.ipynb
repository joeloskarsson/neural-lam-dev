{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5d8017",
   "metadata": {},
   "source": [
    "##  Gridded Model Verification\n",
    "\n",
    "This script verifies output from a ML-based foundation model versus a\n",
    "traditional NWP system for the atmospheric system. The defaults set at the top of\n",
    "this script are tailored to the Alps-Clariden HPC system at CSCS.\n",
    "- The NWP-model is called COSMO-E and is initialised with the ensemble mean of the analysis. Only surface level data is available in the archive at MeteoSwiss.\n",
    "- The ML-model is called Neural-LAM and is initialised with the deterministic analysis.\n",
    "- The Ground Truth is the same deterministic analysis as was used to train the ML-model.\n",
    "- The boundary data for both models is IFS HRES from ECMWF, where the NWP-model got 6 hourly boundary updates and the ML model 12 hourly.\n",
    "\n",
    "For more info about the COSMO model see:\n",
    "- https://www.cosmo-model.org/content/model/cosmo/coreDocumentation/cosmo_io_guide_6.00.pdf\n",
    "- https://www.research-collection.ethz.ch/handle/20.500.11850/720460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0311b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/sadamov/miniforge3/envs/neural-lam/lib/python3.12/site-packages/pyproj/network.py:59: UserWarning: pyproj unable to set PROJ database path.\n",
      "  _set_context_ca_bundle_path(ca_bundle_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pysteps configuration file found at: /users/sadamov/miniforge3/envs/neural-lam/lib/python3.12/site-packages/pysteps/pystepsrc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from pysteps.verification.salscores import sal  # requires scikit-image\n",
    "from scipy.stats import wasserstein_distance, kurtosis, skew\n",
    "from scores.continuous import (\n",
    "    mae,\n",
    "    mse,\n",
    "    rmse,\n",
    ")\n",
    "from scores.continuous.correlation import pearsonr\n",
    "from scores.spatial import fss_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a806b47",
   "metadata": {},
   "source": [
    "**--------> Enter all your user settings in the cell below. <--------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf621a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFAULTS ###\n",
    "# This config will be applied to the data before any plotting. The data will be\n",
    "# sliced and indexed according to the values in this config.\n",
    "PATH_GROUND_TRUTH = \"/iopsstor/scratch/cscs/sadamov/pyprojects_data/neural-lam/cosmo.datastore.zarr\"\n",
    "PATH_NWP = \"/capstor/store/cscs/swissai/a01/sadamov/cosmo_e_forecast.zarr\"\n",
    "PATH_ML = \"/iopsstor/scratch/cscs/sadamov/pyprojects_data/neural-lam/eval_results/preds_7_19_margin_interior_lr_0001_ar_12.zarr\"\n",
    "PATH_BOUNDARY = \"/iopsstor/scratch/cscs/sadamov/pyprojects_data/neural-lam/ifs_7_19_margin_interior.datastore.zarr\"\n",
    "# elapsed forecast duration in steps for the forecast - [0] refers to the first forecast step\n",
    "ELAPSED_FORECAST_DURATION = list(range(0, 120, 1))\n",
    "# Select specific start_times for the forecast (will be used for all variables and metrics)\n",
    "START_TIMES = [None, None]\n",
    "# Select specific plot times for the forecast (will be used to create maps for all variables)\n",
    "PLOT_TIME = \"2020-02-13T00:00:00\"\n",
    "# Selection spatial grid in projection\n",
    "X = [None, None]\n",
    "Y = [None, None]\n",
    "# Map projection settings for plotting\n",
    "PROJECTION = ccrs.RotatedPole(\n",
    "    pole_longitude=190,\n",
    "    pole_latitude=43,\n",
    "    central_rotated_longitude=10,\n",
    ")\n",
    "# Define how variables map between different data sources\n",
    "VARIABLES_GROUND_TRUTH = {\n",
    "    # Surface and near-surface variables\n",
    "    \"T_2M\": \"temperature_2m\",\n",
    "    \"U_10M\": \"wind_u_10m\",\n",
    "    \"V_10M\": \"wind_v_10m\",\n",
    "    \"PMSL\": \"pressure_sea_level\",\n",
    "    \"PS\": \"surface_pressure\",\n",
    "    \"TOT_PREC\": \"precipitation\",\n",
    "    \"ASHFL_S\": \"surface_sensible_heat_flux\",\n",
    "    \"ASOB_S\": \"surface_net_shortwave_radiation\",\n",
    "    \"ATHB_S\": \"surface_net_longwave_radiation\",\n",
    "    # Upper air variables - U component\n",
    "    \"U_lev_6\": \"wind_u_level_6\",\n",
    "    \"U_lev_12\": \"wind_u_level_12\",\n",
    "    \"U_lev_20\": \"wind_u_level_20\",\n",
    "    \"U_lev_27\": \"wind_u_level_27\",\n",
    "    \"U_lev_31\": \"wind_u_level_31\",\n",
    "    \"U_lev_39\": \"wind_u_level_39\",\n",
    "    \"U_lev_45\": \"wind_u_level_45\",\n",
    "    \"U_lev_60\": \"wind_u_level_60\",\n",
    "    # Upper air variables - V component\n",
    "    \"V_lev_6\": \"wind_v_level_6\",\n",
    "    \"V_lev_12\": \"wind_v_level_12\",\n",
    "    \"V_lev_20\": \"wind_v_level_20\",\n",
    "    \"V_lev_27\": \"wind_v_level_27\",\n",
    "    \"V_lev_31\": \"wind_v_level_31\",\n",
    "    \"V_lev_39\": \"wind_v_level_39\",\n",
    "    \"V_lev_45\": \"wind_v_level_45\",\n",
    "    \"V_lev_60\": \"wind_v_level_60\",\n",
    "    # Upper air variables - Pressure\n",
    "    \"PP_lev_6\": \"pressure_level_6\",\n",
    "    \"PP_lev_12\": \"pressure_level_12\",\n",
    "    \"PP_lev_20\": \"pressure_level_20\",\n",
    "    \"PP_lev_27\": \"pressure_level_27\",\n",
    "    \"PP_lev_31\": \"pressure_level_31\",\n",
    "    \"PP_lev_39\": \"pressure_level_39\",\n",
    "    \"PP_lev_45\": \"pressure_level_45\",\n",
    "    \"PP_lev_60\": \"pressure_level_60\",\n",
    "    # Upper air variables - Temperature\n",
    "    \"T_lev_6\": \"temperature_level_6\",\n",
    "    \"T_lev_12\": \"temperature_level_12\",\n",
    "    \"T_lev_20\": \"temperature_level_20\",\n",
    "    \"T_lev_27\": \"temperature_level_27\",\n",
    "    \"T_lev_31\": \"temperature_level_31\",\n",
    "    \"T_lev_39\": \"temperature_level_39\",\n",
    "    \"T_lev_45\": \"temperature_level_45\",\n",
    "    \"T_lev_60\": \"temperature_level_60\",\n",
    "    # Upper air variables - Relative Humidity\n",
    "    \"RELHUM_lev_6\": \"relative_humidity_level_6\",\n",
    "    \"RELHUM_lev_12\": \"relative_humidity_level_12\",\n",
    "    \"RELHUM_lev_20\": \"relative_humidity_level_20\",\n",
    "    \"RELHUM_lev_27\": \"relative_humidity_level_27\",\n",
    "    \"RELHUM_lev_31\": \"relative_humidity_level_31\",\n",
    "    \"RELHUM_lev_39\": \"relative_humidity_level_39\",\n",
    "    \"RELHUM_lev_45\": \"relative_humidity_level_45\",\n",
    "    \"RELHUM_lev_60\": \"relative_humidity_level_60\",\n",
    "    # Upper air variables - Vertical velocity\n",
    "    \"W_lev_6\": \"vertical_velocity_level_6\",\n",
    "    \"W_lev_12\": \"vertical_velocity_level_12\",\n",
    "    \"W_lev_20\": \"vertical_velocity_level_20\",\n",
    "    \"W_lev_27\": \"vertical_velocity_level_27\",\n",
    "    \"W_lev_31\": \"vertical_velocity_level_31\",\n",
    "    \"W_lev_39\": \"vertical_velocity_level_39\",\n",
    "    \"W_lev_45\": \"vertical_velocity_level_45\",\n",
    "    \"W_lev_60\": \"vertical_velocity_level_60\",\n",
    "}\n",
    "VARIABLES_ML = VARIABLES_GROUND_TRUTH\n",
    "VARIABLES_NWP = {\n",
    "    \"wind_u_10m\": \"wind_u_10m\",\n",
    "    \"wind_v_10m\": \"wind_v_10m\",\n",
    "    \"precipitation_1hr\": \"precipitation\",\n",
    "    \"pressure_sea_level\": \"pressure_sea_level\",\n",
    "    \"surface_pressure\": \"surface_pressure\",\n",
    "    \"temperature_2m\": \"temperature_2m\",\n",
    "}\n",
    "VARIABLES_BOUNDARY = {\n",
    "    # Surface and near-surface variables\n",
    "    \"mean_sea_level_pressure\": \"pressure_sea_level\",\n",
    "    \"2m_temperature\": \"temperature_2m\",\n",
    "    \"10m_u_component_of_wind\": \"wind_u_10m\",\n",
    "    \"10m_v_component_of_wind\": \"wind_v_10m\",\n",
    "    \"surface_pressure\": \"surface_pressure\",\n",
    "    # Upper air variables - U component\n",
    "    \"u_component_of_wind100hPa\": \"wind_u_level_6\",\n",
    "    \"u_component_of_wind200hPa\": \"wind_u_level_12\",\n",
    "    \"u_component_of_wind400hPa\": \"wind_u_level_20\",\n",
    "    \"u_component_of_wind600hPa\": \"wind_u_level_27\",\n",
    "    \"u_component_of_wind700hPa\": \"wind_u_level_31\",\n",
    "    \"u_component_of_wind850hPa\": \"wind_u_level_39\",\n",
    "    \"u_component_of_wind925hPa\": \"wind_u_level_45\",\n",
    "    \"u_component_of_wind1000hPa\": \"wind_u_level_60\",\n",
    "    # Upper air variables - V component\n",
    "    \"v_component_of_wind100hPa\": \"wind_v_level_6\",\n",
    "    \"v_component_of_wind200hPa\": \"wind_v_level_12\",\n",
    "    \"v_component_of_wind400hPa\": \"wind_v_level_20\",\n",
    "    \"v_component_of_wind600hPa\": \"wind_v_level_27\",\n",
    "    \"v_component_of_wind700hPa\": \"wind_v_level_31\",\n",
    "    \"v_component_of_wind850hPa\": \"wind_v_level_39\",\n",
    "    \"v_component_of_wind925hPa\": \"wind_v_level_45\",\n",
    "    \"v_component_of_wind1000hPa\": \"wind_v_level_60\",\n",
    "    # Upper air variables - Temperature\n",
    "    \"temperature100hPa\": \"temperature_level_6\",\n",
    "    \"temperature200hPa\": \"temperature_level_12\",\n",
    "    \"temperature400hPa\": \"temperature_level_20\",\n",
    "    \"temperature600hPa\": \"temperature_level_27\",\n",
    "    \"temperature700hPa\": \"temperature_level_31\",\n",
    "    \"temperature850hPa\": \"temperature_level_39\",\n",
    "    \"temperature925hPa\": \"temperature_level_45\",\n",
    "    \"temperature1000hPa\": \"temperature_level_60\",\n",
    "    # Upper air variables - Vertical velocity\n",
    "    \"vertical_velocity100hPa\": \"vertical_velocity_level_6\",\n",
    "    \"vertical_velocity200hPa\": \"vertical_velocity_level_12\",\n",
    "    \"vertical_velocity400hPa\": \"vertical_velocity_level_20\",\n",
    "    \"vertical_velocity600hPa\": \"vertical_velocity_level_27\",\n",
    "    \"vertical_velocity700hPa\": \"vertical_velocity_level_31\",\n",
    "    \"vertical_velocity850hPa\": \"vertical_velocity_level_39\",\n",
    "    \"vertical_velocity925hPa\": \"vertical_velocity_level_45\",\n",
    "    \"vertical_velocity1000hPa\": \"vertical_velocity_level_60\",\n",
    "}\n",
    "\n",
    "VARIABLES_3D = [\n",
    "    \"wind_u_level\",\n",
    "    \"wind_v_level\",\n",
    "    \"pressure_level\",\n",
    "    \"temperature_level\",\n",
    "    \"relative_humidity_level\",\n",
    "    \"vertical_velocity_level\",\n",
    "]\n",
    "\n",
    "# Add units dictionary after the imports\n",
    "VARIABLE_UNITS = {\n",
    "    # Surface and near-surface variables\n",
    "    \"temperature_2m\": \"K\",\n",
    "    \"wind_u_10m\": \"m/s\",\n",
    "    \"wind_v_10m\": \"m/s\",\n",
    "    \"pressure_sea_level\": \"Pa\",\n",
    "    \"surface_pressure\": \"Pa\",\n",
    "    \"precipitation\": \"mm/h\",\n",
    "    \"surface_sensible_heat_flux\": \"W/m²\",\n",
    "    \"surface_net_shortwave_radiation\": \"W/m²\",\n",
    "    \"surface_net_longwave_radiation\": \"W/m²\",\n",
    "    # Upper air variables\n",
    "    \"wind_u_level\": \"m/s\",\n",
    "    \"wind_v_level\": \"m/s\",\n",
    "    \"pressure_level\": \"hPa\",\n",
    "    \"temperature_level\": \"K\",\n",
    "    \"relative_humidity_level\": \"%\",\n",
    "    \"vertical_velocity_level\": \"Pa/s\",\n",
    "}\n",
    "\n",
    "# Add level-specific units based on VARIABLES_GROUND_TRUTH\n",
    "required_levels = set()\n",
    "for key in VARIABLES_GROUND_TRUTH.keys():\n",
    "    if \"lev_\" in key:\n",
    "        level = int(key.split(\"_\")[-1])\n",
    "        required_levels.add(level)\n",
    "\n",
    "for level in required_levels:\n",
    "    VARIABLE_UNITS[f\"wind_u_level_{level}\"] = \"m/s\"\n",
    "    VARIABLE_UNITS[f\"wind_v_level_{level}\"] = \"m/s\"\n",
    "    VARIABLE_UNITS[f\"pressure_level_{level}\"] = \"hPa\"\n",
    "    VARIABLE_UNITS[f\"temperature_level_{level}\"] = \"K\"\n",
    "    VARIABLE_UNITS[f\"relative_humidity_level_{level}\"] = \"%\"\n",
    "    VARIABLE_UNITS[f\"vertical_velocity_level_{level}\"] = \"Pa/s\"\n",
    "\n",
    "# For some plots a random time step sample is selected\n",
    "RANDOM_SEED = 42\n",
    "DPI = 100\n",
    "# Subsample the data for faster plotting, 10 refers to every 10th element\n",
    "SUBSAMPLE_HISTOGRAM = 10\n",
    "# Subsample the data for FSS threshold calculation, 1e7 refers to the number of elements\n",
    "SUBSAMPLE_FSS_THRESHOLD = 1e7\n",
    "\n",
    "CHECK_MISSING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b2e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for plots and tables\n",
    "Path(\"plots\").mkdir(exist_ok=True)\n",
    "Path(\"tables\").mkdir(exist_ok=True)\n",
    "\n",
    "# Colorblind-friendly color palette\n",
    "COLORS = {\n",
    "    \"ground_truth\": \"#000000\",  # Black\n",
    "    \"ml\": \"#E69F00\",  # Orange\n",
    "    \"nwp\": \"#56B4E9\",  # Light blue\n",
    "    \"error\": \"#CC79A7\",  # Pink\n",
    "}\n",
    "\n",
    "# Line styles and markers for accessibility\n",
    "LINE_STYLES = {\n",
    "    \"ground_truth\": (\"solid\", \"o\"),\n",
    "    \"ml\": (\"dashed\", \"s\"),\n",
    "    \"nwp\": (\"dotted\", \"^\"),\n",
    "}\n",
    "\n",
    "# Colorblind-friendly colormap for 2D plots\n",
    "COLORMAP = \"viridis\"\n",
    "\n",
    "\n",
    "def save_plot(fig, name, time=None):\n",
    "    \"\"\"Helper function to save plots consistently\"\"\"\n",
    "    if time is not None:\n",
    "        name = f\"{name}_{time.dt.strftime('%Y%m%d_%H').values}\"\n",
    "    fig.savefig(f\"plots/{name}.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    # fig.savefig(f\"plots/{name}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "\n",
    "def export_table(df, name, caption=\"\"):\n",
    "    \"\"\"Helper function to export tables consistently\"\"\"\n",
    "    # Export to LaTeX with caption\n",
    "    latex_str = df.to_latex(\n",
    "        float_format=\"%.4f\", caption=caption, label=f\"tab:{name}\"\n",
    "    )\n",
    "    with open(f\"tables/{name}.tex\", \"w\") as f:\n",
    "        f.write(latex_str)\n",
    "\n",
    "    # Export to CSV\n",
    "    df.to_csv(f\"tables/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ml = xr.open_zarr(PATH_ML)\n",
    "ds_ml = ds_ml.sel(state_feature=list(VARIABLES_ML.keys()))\n",
    "ds_ml = ds_ml.sel(y=slice(*Y), x=slice(*X))\n",
    "ds_ml = ds_ml.sel(start_time=slice(*START_TIMES))\n",
    "for feature in ds_ml.state_feature.values:\n",
    "    ds_ml[VARIABLES_ML[feature]] = ds_ml[\"state\"].sel(state_feature=feature)\n",
    "forecast_times = (\n",
    "    ds_ml.start_time.values[:, None] + ds_ml.elapsed_forecast_duration.values\n",
    ")\n",
    "ds_ml = ds_ml.assign_coords(\n",
    "    forecast_time=((\"start_time\", \"elapsed_forecast_duration\"), forecast_times)\n",
    ")\n",
    "ds_ml = ds_ml.drop_vars([\"state\", \"state_feature\", \"time\"])\n",
    "ds_ml = ds_ml.transpose(\"start_time\", \"elapsed_forecast_duration\", \"x\", \"y\")\n",
    "ds_ml = ds_ml[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"elapsed_forecast_duration\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_ML.values(),\n",
    "    ]\n",
    "]\n",
    "ds_ml = ds_ml.isel(elapsed_forecast_duration=ELAPSED_FORECAST_DURATION)\n",
    "ds_ml = ds_ml.compute()\n",
    "\n",
    "ds_ml_first_timestep = (\n",
    "    ds_ml.isel(elapsed_forecast_duration=0)\n",
    "    .rename({\"forecast_time\": \"time\"})\n",
    "    .swap_dims({\"start_time\": \"time\"})\n",
    "    .drop_vars([\"start_time\", \"elapsed_forecast_duration\"])\n",
    ").compute()\n",
    "\n",
    "ds_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMES = np.unique(ds_ml.forecast_time.values.flatten())\n",
    "START_TIMES = ds_ml.start_time\n",
    "STEP_SIZE = ds_ml.elapsed_forecast_duration.diff(\n",
    "    \"elapsed_forecast_duration\"\n",
    ").values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf42e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gt = xr.open_zarr(PATH_GROUND_TRUTH)\n",
    "ds_gt = ds_gt.set_index(grid_index=[\"y\", \"x\"]).unstack(\"grid_index\")\n",
    "ds_gt = ds_gt.sel(y=slice(*Y), x=slice(*X))\n",
    "ds_gt = ds_gt.sel(state_feature=list(VARIABLES_ML.keys()))\n",
    "ds_gt = ds_gt.sel(split_name=\"test\").drop_dims([\n",
    "    \"forcing_feature\",\n",
    "    \"static_feature\",\n",
    "    \"split_part\",\n",
    "])\n",
    "for feature in ds_gt.state_feature.values:\n",
    "    ds_gt[VARIABLES_ML[feature]] = ds_gt[\"state\"].sel(state_feature=feature)\n",
    "ds_gt = ds_gt.drop_vars([\n",
    "    \"state\",\n",
    "    \"state_feature\",\n",
    "    \"state_feature_units\",\n",
    "    \"state_feature_long_name\",\n",
    "    \"state_feature_source_dataset\",\n",
    "    \"state__train__diff_mean\",\n",
    "    \"state__train__diff_std\",\n",
    "    \"state__train__mean\",\n",
    "    \"state__train__std\",\n",
    "])\n",
    "ds_gt = ds_gt.transpose(\"time\", \"x\", \"y\")\n",
    "ds_gt = ds_gt[\n",
    "    [\n",
    "        \"time\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_GROUND_TRUTH.values(),\n",
    "    ]\n",
    "]\n",
    "ds_gt_first_timestep = (\n",
    "    ds_gt.sel(\n",
    "        time=START_TIMES + np.timedelta64(ELAPSED_FORECAST_DURATION[0] + 1, \"h\")\n",
    "    )\n",
    "    .swap_dims({\"start_time\": \"time\"})\n",
    "    .drop_vars([\"start_time\"])\n",
    ")\n",
    "ds_gt_first_timestep = ds_gt_first_timestep.compute()\n",
    "ds_gt = ds_gt.sel(time=TIMES)\n",
    "ds_gt = ds_gt.compute()\n",
    "ds_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nwp = xr.open_zarr(PATH_NWP)\n",
    "ds_nwp = ds_nwp.sel(y=slice(*Y), x=slice(*X), time=START_TIMES)\n",
    "# The NWP data starts at lead time 0 = start_time\n",
    "ds_nwp = ds_nwp.drop_isel(lead_time=0).isel(lead_time=ELAPSED_FORECAST_DURATION)\n",
    "ds_nwp = ds_nwp[VARIABLES_NWP.keys()].rename(VARIABLES_NWP)\n",
    "ds_nwp = ds_nwp.rename_dims({\"lead_time\": \"elapsed_forecast_duration\"})\n",
    "ds_nwp = ds_nwp.rename_vars({\"lead_time\": \"elapsed_forecast_duration\"})\n",
    "forecast_times = (\n",
    "    ds_nwp.start_time.values[:, None] + ds_nwp.elapsed_forecast_duration.values\n",
    ")\n",
    "ds_nwp = ds_nwp.assign_coords(\n",
    "    forecast_time=((\"start_time\", \"elapsed_forecast_duration\"), forecast_times)\n",
    ")\n",
    "ds_nwp = ds_nwp.drop_vars([\"time\"])\n",
    "ds_nwp = ds_nwp.transpose(\"start_time\", \"elapsed_forecast_duration\", \"x\", \"y\")\n",
    "ds_nwp = ds_nwp[\n",
    "    [\n",
    "        \"start_time\",\n",
    "        \"elapsed_forecast_duration\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        *VARIABLES_NWP.values(),\n",
    "    ]\n",
    "]\n",
    "ds_nwp = ds_nwp.compute()\n",
    "\n",
    "ds_nwp_first_timestep = (\n",
    "    ds_nwp.isel(elapsed_forecast_duration=0)\n",
    "    .rename({\"forecast_time\": \"time\"})\n",
    "    .swap_dims({\"start_time\": \"time\"})\n",
    "    .drop_vars([\"start_time\", \"elapsed_forecast_duration\"])\n",
    ").compute()\n",
    "\n",
    "ds_nwp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46114d2",
   "metadata": {},
   "source": [
    "Check for missing data in any of the variables. If you have missing data, you need to handle it before running the verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b77c2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if CHECK_MISSING:\n",
    "    with LocalCluster(\n",
    "        n_workers=16,\n",
    "        threads_per_worker=1,\n",
    "        memory_limit=\"16GB\",\n",
    "    ) as cluster:\n",
    "        with Client(cluster) as client:\n",
    "            missing_counts = dask.compute(\n",
    "                {\n",
    "                    var: ds_gt[var].isnull().sum().values\n",
    "                    for var in ds_gt.data_vars\n",
    "                },\n",
    "                {\n",
    "                    var: ds_nwp[var].isnull().sum().values\n",
    "                    for var in ds_nwp.data_vars\n",
    "                },\n",
    "                {\n",
    "                    var: ds_ml[var].isnull().sum().values\n",
    "                    for var in ds_ml.data_vars\n",
    "                },\n",
    "            )\n",
    "    # Unpack results\n",
    "    gt_missing, nwp_missing, ml_missing = missing_counts\n",
    "\n",
    "    # Print results\n",
    "    print(\"Ground Truth\")\n",
    "    for var, count in gt_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")\n",
    "\n",
    "    print(\"\\nNWP Model\")\n",
    "    for var, count in nwp_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")\n",
    "\n",
    "    print(\"\\nML Model\")\n",
    "    for var, count in ml_missing.items():\n",
    "        print(f\"{var}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds_gt.sizes[\"x\"] == ds_ml.sizes[\"x\"]\n",
    "assert ds_gt.sizes[\"x\"] == ds_nwp.sizes[\"x\"]\n",
    "assert ds_gt.sizes[\"y\"] == ds_ml.sizes[\"y\"]\n",
    "assert ds_gt.sizes[\"y\"] == ds_nwp.sizes[\"y\"]\n",
    "assert ds_gt.sizes[\"time\"] == len(\n",
    "    np.unique(ds_ml.forecast_time.values.flatten())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eadd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates\n",
    "if hasattr(ds_gt, \"longitude\") and hasattr(ds_gt, \"latitude\"):\n",
    "    lons = ds_gt.longitude.values\n",
    "    lats = ds_gt.latitude.values\n",
    "elif hasattr(ds_gt, \"lon\") and hasattr(ds_gt, \"lat\"):\n",
    "    lons = ds_gt.lon.values\n",
    "    lats = ds_gt.lat.values\n",
    "\n",
    "lon_min = lons.min()\n",
    "lon_max = lons.max()\n",
    "lat_min = lats.min()\n",
    "lat_max = lats.max()\n",
    "\n",
    "# Transform domain bounds to rotated coordinates\n",
    "transformer = PROJECTION.transform_points(\n",
    "    ccrs.PlateCarree(),\n",
    "    np.array([lon_min, lon_max]),\n",
    "    np.array([lat_min, lat_max]),\n",
    ")\n",
    "\n",
    "# Get rotated coordinate bounds\n",
    "rot_lon_min, rot_lon_max = transformer[:, 0].min(), transformer[:, 0].max()\n",
    "rot_lat_min, rot_lat_max = transformer[:, 1].min(), transformer[:, 1].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da85c5",
   "metadata": {},
   "source": [
    "### 1. Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c76fb",
   "metadata": {},
   "source": [
    "**Random Time Selection:** A random time step is selected to avoid bias in the comparison, ensuring that the assessment is representative of typical model performance.\n",
    "\n",
    "**Consistent Color Scales:** By setting the same minimum and maximum values across all datasets for each variable, we ensure that color differences in the plots reflect true discrepancies, not artifacts of scaling.\n",
    "\n",
    "**Spatial Patterns:** The plots reveal how the ML model and NWP model represent geographical features like weather fronts, high and low-pressure systems, and temperature gradients. Visual comparisons can immediately highlight areas where the models perform well or poorly, guiding further investigation.\n",
    "\n",
    "**Edge Effects:** Near the boundaries, artifacts may occur as the model does not calculate a loss in the boundary region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76799646",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ds_boundary = xr.open_zarr(PATH_BOUNDARY)\n",
    "\n",
    "temporal_dim = \"time\" if \"time\" in ds_boundary.dims else \"analysis_time\"\n",
    "forecast_duration_dim = (\n",
    "    \"elapsed_forecast_duration\"\n",
    "    if \"elapsed_forecast_duration\" in ds_boundary.dims\n",
    "    else None\n",
    ")\n",
    "dims_to_transpose = [\n",
    "    dim\n",
    "    for dim in [temporal_dim, forecast_duration_dim, \"latitude\", \"longitude\"]\n",
    "    if dim is not None\n",
    "]\n",
    "\n",
    "ds_boundary = ds_boundary.sel(forcing_feature=list(VARIABLES_BOUNDARY.keys()))\n",
    "ds_boundary = ds_boundary.sel(split_name=\"test\").drop_dims([\n",
    "    \"split_part\",\n",
    "    \"static_feature\",\n",
    "])\n",
    "for feature in ds_boundary.forcing_feature.values:\n",
    "    ds_boundary[VARIABLES_BOUNDARY[feature]] = ds_boundary[\"forcing\"].sel(\n",
    "        forcing_feature=feature\n",
    "    )\n",
    "ds_boundary = ds_boundary.drop_vars([\n",
    "    \"forcing\",\n",
    "    \"forcing_feature\",\n",
    "    \"forcing_feature_units\",\n",
    "    \"forcing_feature_long_name\",\n",
    "    \"forcing_feature_source_dataset\",\n",
    "    \"forcing__train__diff_mean\",\n",
    "    \"forcing__train__diff_std\",\n",
    "    \"forcing__train__mean\",\n",
    "    \"forcing__train__std\",\n",
    "])\n",
    "ds_boundary = ds_boundary.set_index(grid_index=[\"latitude\", \"longitude\"])\n",
    "ds_boundary = ds_boundary.unstack(\"grid_index\")\n",
    "ds_boundary = ds_boundary.transpose(*dims_to_transpose)\n",
    "longitude_new = np.where(\n",
    "    ds_boundary[\"longitude\"] > 180,\n",
    "    ds_boundary[\"longitude\"] - 360,\n",
    "    ds_boundary[\"longitude\"],\n",
    ")\n",
    "ds_boundary = ds_boundary.assign_coords(longitude=longitude_new).sortby([\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "])\n",
    "\n",
    "\n",
    "lon_mesh, lat_mesh = np.meshgrid(ds_boundary.longitude, ds_boundary.latitude)\n",
    "ds_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_maps(\n",
    "    ds_gt,\n",
    "    ds_ml,\n",
    "    ds_nwp,\n",
    "    ds_boundary=None,\n",
    "    var=None,\n",
    "    elapsed_forecast_duration=None,\n",
    "    plot_time=None,\n",
    "    random_seed=42,\n",
    "):\n",
    "    \"\"\"Create comparison maps for model outputs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds_gt : xarray.Dataset\n",
    "        Ground truth dataset\n",
    "    ds_ml : xarray.Dataset\n",
    "        ML model predictions\n",
    "    ds_nwp : xarray.Dataset\n",
    "        NWP model predictions (can be None)\n",
    "    ds_boundary : xarray.Dataset, optional\n",
    "        Boundary condition dataset\n",
    "    var : str, optional\n",
    "        Variable to plot (if None, plots all variables)\n",
    "    elapsed_forecast_duration : int, optional\n",
    "        Specific elapsed forecast duration to plot (if None, uses first timestep)\n",
    "    plot_time : str, optional\n",
    "        Specific time to plot (format: \"YYYY-MM-DD HH:MM:SS\")\n",
    "    random_seed : int, default=42\n",
    "        Random seed for time selection\n",
    "    \"\"\"\n",
    "    # Handle variable selection\n",
    "    variables = [var] if var else VARIABLES_GROUND_TRUTH.values()\n",
    "\n",
    "    if plot_time is None:\n",
    "        random.seed(random_seed)\n",
    "        time_index = random.randint(0, len(ds_gt.time) - 1)\n",
    "        time_selected = ds_ml.time[time_index].values\n",
    "    else:\n",
    "        time_selected = plot_time\n",
    "\n",
    "    if \"elapsed_forecast_duration\" in ds_ml:\n",
    "        ds_ml_time = ds_ml.sel(\n",
    "            start_time=time_selected,\n",
    "            elapsed_forecast_duration=elapsed_forecast_duration,\n",
    "        )\n",
    "        ds_nwp_time = (\n",
    "            ds_nwp.sel(\n",
    "                start_time=time_selected,\n",
    "                elapsed_forecast_duration=elapsed_forecast_duration,\n",
    "            )\n",
    "            if ds_nwp is not None\n",
    "            else None\n",
    "        )\n",
    "        ds_gt_time = ds_gt.sel(time=ds_ml_time.forecast_time)\n",
    "    else:\n",
    "        ds_ml_time = ds_ml.sel(time=time_selected)\n",
    "        ds_nwp_time = (\n",
    "            ds_nwp.sel(time=time_selected) if ds_nwp is not None else None\n",
    "        )\n",
    "        ds_gt_time = ds_gt.sel(time=time_selected)\n",
    "\n",
    "    # Get coordinates\n",
    "    lons = ds_gt.longitude if hasattr(ds_gt, \"longitude\") else ds_gt.lon\n",
    "    lats = ds_gt.latitude if hasattr(ds_gt, \"latitude\") else ds_gt.lat\n",
    "\n",
    "    for var in variables:\n",
    "        # Determine number of subplots based on NWP data availability\n",
    "        n_plots = 3 if (ds_nwp_time is not None and var in ds_nwp_time) else 2\n",
    "        fig, axes = plt.subplots(\n",
    "            1,\n",
    "            n_plots,\n",
    "            figsize=(7 * n_plots, 4),\n",
    "            dpi=DPI,\n",
    "            subplot_kw={\"projection\": PROJECTION},\n",
    "        )\n",
    "        axes = np.atleast_1d(axes)\n",
    "\n",
    "        # Select data\n",
    "        ds_var = ds_gt_time[var]\n",
    "        ds_ml_var = ds_ml_time[var]\n",
    "\n",
    "        # Initialize arrays for min/max calculation\n",
    "        arrays_for_minmax = [ds_var.values, ds_ml_var.values]\n",
    "\n",
    "        # Add NWP data if available\n",
    "        if ds_nwp_time is not None and var in ds_nwp_time:\n",
    "            ds_nwp_var = ds_nwp_time[var]\n",
    "            arrays_for_minmax.append(ds_nwp_var.values)\n",
    "\n",
    "        # Add boundary data if available\n",
    "        if ds_boundary is not None and var in ds_boundary:\n",
    "            if \"elapsed_forecast_duration\" in ds_boundary:\n",
    "                # During evaluation the model has only seen forecasts that were\n",
    "                # realistically available. The plotted time steps is step t0\n",
    "                # t-2, t-1 -> t0. Therefore, we need to subtract one step and then\n",
    "                # select the closest boundary forecast from the past.\n",
    "                # Exact matches are not allowed, forecast analysis_time must\n",
    "                # be in the past.\n",
    "                if (\n",
    "                    ds_boundary.sel(\n",
    "                        analysis_time=time_selected - STEP_SIZE,\n",
    "                        method=\"pad\",\n",
    "                    ).analysis_time.values\n",
    "                    == time_selected - STEP_SIZE\n",
    "                ):\n",
    "                    steps = 2\n",
    "                else:\n",
    "                    steps = 1\n",
    "\n",
    "                ds_boundary_var = ds_boundary[var].sel(\n",
    "                    analysis_time=time_selected - steps * STEP_SIZE,\n",
    "                    method=\"pad\",\n",
    "                )\n",
    "                forecast_times = (\n",
    "                    ds_boundary_var.analysis_time.values\n",
    "                    + ds_boundary_var.elapsed_forecast_duration.values\n",
    "                )\n",
    "                ds_boundary_var = ds_boundary_var.assign_coords(\n",
    "                    forecast_time=(\n",
    "                        \"elapsed_forecast_duration\",\n",
    "                        forecast_times,\n",
    "                    )\n",
    "                ).set_xindex(\"forecast_time\")\n",
    "                ds_boundary_var = ds_boundary_var.sel(\n",
    "                    forecast_time=time_selected, method=\"pad\"\n",
    "                )\n",
    "                print(\n",
    "                    \"Boundary Start_Time is: \",\n",
    "                    ds_boundary_var.analysis_time.values,\n",
    "                )\n",
    "            else:\n",
    "                ds_boundary_var = ds_boundary[var].sel(\n",
    "                    time=time_selected, method=\"pad\"\n",
    "                )\n",
    "            arrays_for_minmax.append(ds_boundary_var.values)\n",
    "\n",
    "        # Calculate global min/max\n",
    "        combined_array = np.concatenate([\n",
    "            arr.flatten() for arr in arrays_for_minmax\n",
    "        ])\n",
    "        vmin, vmax = np.nanmin(combined_array), np.nanmax(combined_array)\n",
    "\n",
    "        # Plot boundaries if available\n",
    "        if ds_boundary is not None and var in ds_boundary:\n",
    "            for ax in axes:\n",
    "                ax.contourf(\n",
    "                    lon_mesh,\n",
    "                    lat_mesh,\n",
    "                    ds_boundary_var.values,\n",
    "                    transform=ccrs.PlateCarree(),\n",
    "                    cmap=\"viridis\",\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                    alpha=0.5,\n",
    "                    levels=20,\n",
    "                )\n",
    "\n",
    "        # Plot ground truth\n",
    "        im0 = axes[0].pcolormesh(\n",
    "            lons,\n",
    "            lats,\n",
    "            ds_var.values,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=\"viridis\",\n",
    "            shading=\"auto\",\n",
    "        )\n",
    "        axes[0].set_title(\"Ground Truth\")\n",
    "\n",
    "        # Plot order depends on NWP availability\n",
    "        plot_idx = 1\n",
    "        if ds_nwp_time is not None and var in ds_nwp_time:\n",
    "            axes[plot_idx].pcolormesh(\n",
    "                lons,\n",
    "                lats,\n",
    "                ds_nwp_var.values,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                cmap=\"viridis\",\n",
    "                shading=\"auto\",\n",
    "            )\n",
    "            axes[plot_idx].set_title(\"NWP Model Prediction\")\n",
    "            plot_idx += 1\n",
    "\n",
    "        # Plot ML prediction (always last)\n",
    "        axes[plot_idx].pcolormesh(\n",
    "            lons,\n",
    "            lats,\n",
    "            ds_ml_var.values,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=\"viridis\",\n",
    "            shading=\"auto\",\n",
    "        )\n",
    "        axes[plot_idx].set_title(\"ML Model Prediction\")\n",
    "\n",
    "        # Add common features to all plots\n",
    "        for ax in axes:\n",
    "            ax.coastlines(resolution=\"50m\")\n",
    "            ax.add_feature(cfeature.BORDERS, linestyle=\"-\", alpha=0.7)\n",
    "            gl = ax.gridlines(\n",
    "                draw_labels=True, dms=True, x_inline=False, y_inline=False\n",
    "            )\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "\n",
    "        # Add colorbar\n",
    "        cbar_ax = fig.add_axes([0.2, -0.05, 0.6, 0.05])\n",
    "        cbar = fig.colorbar(im0, cax=cbar_ax, orientation=\"horizontal\")\n",
    "        cbar.set_label(VARIABLE_UNITS[var])\n",
    "\n",
    "        # Adjust subplot spacing\n",
    "        plt.subplots_adjust(bottom=0.15, hspace=0.05, wspace=0.05)\n",
    "\n",
    "        if elapsed_forecast_duration is not None:\n",
    "            title = f\"{var} at {str(time_selected.dt.date.values)} - {time_selected.dt.hour.values:02d} UTC and Elapsed Forecast Duration +{int(elapsed_forecast_duration.values / 1e9 / 3600)}h\"\n",
    "            save_name = f\"map_{var}_leadtime_{int(elapsed_forecast_duration.values):02d}\"\n",
    "        else:\n",
    "            title = f\"{var} at {str(time_selected.dt.date.values)} - {time_selected.dt.hour.values:02d} UTC\"\n",
    "            save_name = f\"map_{var}\"\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        save_plot(fig, f\"{save_name}\", time_selected)\n",
    "        plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0382c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_TIME is None:\n",
    "    time_selected = None\n",
    "else:\n",
    "    time_selected = ds_gt_first_timestep.sel(\n",
    "        time=pd.to_datetime(PLOT_TIME)\n",
    "        + ds_ml.isel(\n",
    "            elapsed_forecast_duration=ELAPSED_FORECAST_DURATION[0]\n",
    "        ).elapsed_forecast_duration.values\n",
    "    ).time\n",
    "\n",
    "create_comparison_maps(\n",
    "    ds_gt=ds_gt_first_timestep,\n",
    "    ds_ml=ds_ml_first_timestep,\n",
    "    ds_nwp=ds_nwp_first_timestep,\n",
    "    ds_boundary=ds_boundary,\n",
    "    plot_time=time_selected,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73b3c1",
   "metadata": {},
   "source": [
    "#### Mean Error Plot For The Same Time Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92322ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_maps(\n",
    "    ds_gt,\n",
    "    ds_ml,\n",
    "    ds_nwp=None,\n",
    "    var=None,\n",
    "    elapsed_forecast_duration=None,\n",
    "    plot_time=None,\n",
    "    random_seed=42,\n",
    "):\n",
    "    \"\"\"Create error maps for model outputs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds_gt : xarray.Dataset\n",
    "        Ground truth dataset\n",
    "    ds_ml : xarray.Dataset\n",
    "        ML model predictions\n",
    "    ds_nwp : xarray.Dataset, optional\n",
    "        NWP model predictions\n",
    "    var : str, optional\n",
    "        Variable to plot (if None, plots all variables)\n",
    "    elapsed_forecast_duration : int, optional\n",
    "        Specific elapsed forecast duration to plot (if None, uses first timestep)\n",
    "    plot_time : str, optional\n",
    "        Specific time to plot (format: \"YYYY-MM-DD HH:MM:SS\")\n",
    "    random_seed : int, default=42\n",
    "        Random seed for time selection\n",
    "    \"\"\"\n",
    "    # Handle variable selection\n",
    "    variables = [var] if var else VARIABLES_GROUND_TRUTH.values()\n",
    "\n",
    "    if plot_time is None:\n",
    "        random.seed(random_seed)\n",
    "        time_index = random.randint(0, len(ds_gt.time) - 1)\n",
    "        time_selected = ds_ml.time[time_index].values\n",
    "    else:\n",
    "        time_selected = plot_time\n",
    "\n",
    "    if \"elapsed_forecast_duration\" in ds_ml:\n",
    "        ds_ml_time = ds_ml.sel(\n",
    "            start_time=time_selected,\n",
    "            elapsed_forecast_duration=elapsed_forecast_duration,\n",
    "        )\n",
    "        ds_nwp_time = (\n",
    "            ds_nwp.sel(\n",
    "                start_time=time_selected,\n",
    "                elapsed_forecast_duration=elapsed_forecast_duration,\n",
    "            )\n",
    "            if ds_nwp is not None\n",
    "            else None\n",
    "        )\n",
    "        ds_gt_time = ds_gt.sel(time=ds_ml_time.forecast_time)\n",
    "    else:\n",
    "        ds_ml_time = ds_ml.sel(time=time_selected)\n",
    "        ds_nwp_time = (\n",
    "            ds_nwp.sel(time=time_selected) if ds_nwp is not None else None\n",
    "        )\n",
    "        ds_gt_time = ds_gt.sel(time=time_selected)\n",
    "\n",
    "    # Get coordinates\n",
    "    lons = ds_gt.longitude if hasattr(ds_gt, \"longitude\") else ds_gt.lon\n",
    "    lats = ds_gt.latitude if hasattr(ds_gt, \"latitude\") else ds_gt.lat\n",
    "\n",
    "    for var in variables:\n",
    "        # Determine number of plots based on NWP data availability\n",
    "        n_plots = 1 if (ds_nwp_time is None or var not in ds_nwp_time) else 2\n",
    "        fig, axes = plt.subplots(\n",
    "            1,\n",
    "            n_plots,\n",
    "            figsize=(7 * n_plots, 4),\n",
    "            dpi=DPI,\n",
    "            subplot_kw={\"projection\": PROJECTION},\n",
    "        )\n",
    "        axes = np.atleast_1d(axes)\n",
    "\n",
    "        # Calculate errors\n",
    "        ds_var = ds_gt_time[var]\n",
    "        ds_ml_var = ds_ml_time[var]\n",
    "        error_ml = ds_ml_var - ds_var\n",
    "\n",
    "        # Initialize arrays for min/max calculation\n",
    "        arrays_for_minmax = [error_ml.values]\n",
    "\n",
    "        if ds_nwp_time is not None and var in ds_nwp_time:\n",
    "            ds_nwp_var = ds_nwp_time[var]\n",
    "            error_nwp = ds_nwp_var - ds_var\n",
    "            arrays_for_minmax.append(error_nwp.values)\n",
    "\n",
    "        # Calculate global min/max for symmetric colorbar\n",
    "        max_abs_error = np.max(np.abs(arrays_for_minmax))\n",
    "        vmin, vmax = -max_abs_error, max_abs_error\n",
    "\n",
    "        plot_idx = 0\n",
    "        if ds_nwp_time is not None and var in ds_nwp_time:\n",
    "            axes[plot_idx].pcolormesh(\n",
    "                lons,\n",
    "                lats,\n",
    "                error_nwp.values,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                cmap=\"RdBu\",\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                shading=\"auto\",\n",
    "            )\n",
    "            axes[plot_idx].set_title(\"NWP Model Error\")\n",
    "            plot_idx += 1\n",
    "\n",
    "        im1 = axes[plot_idx].pcolormesh(\n",
    "            lons,\n",
    "            lats,\n",
    "            error_ml.values,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=\"RdBu\",\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            shading=\"auto\",\n",
    "        )\n",
    "        axes[plot_idx].set_title(\"ML Model Error\")\n",
    "\n",
    "        # Add common features to all plots\n",
    "        for ax in axes:\n",
    "            ax.coastlines(resolution=\"50m\")\n",
    "            ax.add_feature(cfeature.BORDERS, linestyle=\"-\", alpha=0.7)\n",
    "            gl = ax.gridlines(\n",
    "                draw_labels=True, dms=True, x_inline=False, y_inline=False\n",
    "            )\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "\n",
    "        # Add colorbar\n",
    "        cbar_ax = fig.add_axes([0.2, -0.05, 0.6, 0.05])\n",
    "        cbar = fig.colorbar(im1, cax=cbar_ax, orientation=\"horizontal\")\n",
    "        cbar.set_label(f\"Error in {VARIABLE_UNITS[var]}\")\n",
    "\n",
    "        # Adjust subplot spacing\n",
    "        plt.subplots_adjust(bottom=0.15, hspace=0.05, wspace=0.05)\n",
    "\n",
    "        if elapsed_forecast_duration is not None:\n",
    "            title = f\"Error in {var} at {str(time_selected.dt.date.values)} - {time_selected.dt.hour.values:02d} UTC and Elapsed Forecast Duration +{int(elapsed_forecast_duration.values / 1e9 / 3600)}h\"\n",
    "            save_name = f\"errormap_{var}_leadtime_{int(elapsed_forecast_duration.values):02d}\"\n",
    "        else:\n",
    "            title = f\"Error in {var} at {str(time_selected.dt.date.values)} - {time_selected.dt.hour.values:02d} UTC\"\n",
    "            save_name = f\"errormap_{var}\"\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        save_plot(fig, save_name, time_selected)\n",
    "        plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_TIME is None:\n",
    "    time_selected = None\n",
    "else:\n",
    "    time_selected = ds_gt_first_timestep.sel(\n",
    "        time=pd.to_datetime(PLOT_TIME)\n",
    "        + ds_ml.isel(\n",
    "            elapsed_forecast_duration=ELAPSED_FORECAST_DURATION[0]\n",
    "        ).elapsed_forecast_duration.values\n",
    "    ).time\n",
    "\n",
    "# Add this at the end of your script to create error maps for different elapsed forecast durations\n",
    "create_error_maps(\n",
    "    ds_gt=ds_gt_first_timestep,\n",
    "    ds_ml=ds_ml_first_timestep,\n",
    "    ds_nwp=ds_nwp_first_timestep,\n",
    "    plot_time=time_selected,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df26997",
   "metadata": {},
   "source": [
    "### 2. Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74267537",
   "metadata": {},
   "source": [
    "By examining these distributions, we can assess whether the ML model and NWP model accurately capture the variability and frequency of different atmospheric states.\n",
    "\n",
    "**Distribution Shape:** The histograms show whether the models replicate the skewness, kurtosis, and overall shape of the ground truth data distributions.\n",
    "\n",
    "**Extreme Values:** Identifying how the models handle extreme conditions, such as unusually high or low temperatures, is crucial for weather prediction and risk assessment.\n",
    "\n",
    "**Normalization Needs:** Differences in scale between variables suggest that normalization may be necessary for accurate comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c28a1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for variable_name in VARIABLES_GROUND_TRUTH.values():\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI)\n",
    "\n",
    "    # Sample 10% of each dimension\n",
    "    ds_gt_sampled = ds_gt[variable_name].isel(\n",
    "        time=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "        x=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "        y=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "    )\n",
    "    ds_ml_sampled = ds_ml_first_timestep[variable_name].isel(\n",
    "        time=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "        x=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "        y=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "    )\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    data_gt = ds_gt_sampled.values.flatten()\n",
    "    data_ml = ds_ml_sampled.values.flatten()\n",
    "\n",
    "    ax.hist(\n",
    "        data_gt,\n",
    "        bins=500,\n",
    "        density=True,\n",
    "        color=COLORS[\"ground_truth\"],\n",
    "        label=\"Ground Truth\",\n",
    "    )\n",
    "    # Plot NWP if available\n",
    "    if variable_name in ds_nwp_first_timestep:\n",
    "        ds_nwp_sampled = ds_nwp_first_timestep[variable_name].isel(\n",
    "            time=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "            x=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "            y=slice(None, None, SUBSAMPLE_HISTOGRAM),\n",
    "        )\n",
    "        data_nwp = ds_nwp_sampled.values.flatten()\n",
    "        ax.hist(\n",
    "            data_nwp,\n",
    "            bins=500,\n",
    "            alpha=0.8,\n",
    "            density=True,\n",
    "            color=COLORS[\"nwp\"],\n",
    "            label=\"NWP Model Prediction\",\n",
    "        )\n",
    "\n",
    "    # Create histograms for ML and ground truth\n",
    "    ax.hist(\n",
    "        data_ml,\n",
    "        bins=500,\n",
    "        alpha=0.8,\n",
    "        density=True,\n",
    "        color=COLORS[\"ml\"],\n",
    "        label=\"ML Model Prediction\",\n",
    "    )\n",
    "\n",
    "    # Add labels and title\n",
    "    units = VARIABLE_UNITS[variable_name]\n",
    "    ax.set_title(f\"Distribution of {variable_name} ({units})\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Calculate skewness and kurtosis\n",
    "    stats_gt = f\"Ground Truth:\\nSkewness: {skew(data_gt):.2f}\\nKurtosis: {kurtosis(data_gt):.2f}\"\n",
    "    stats_ml = f\"ML Model:\\nSkewness: {skew(data_ml):.2f}\\nKurtosis: {kurtosis(data_ml):.2f}\"\n",
    "\n",
    "    # Combine stats\n",
    "    stats_text = stats_gt + \"\\n\\n\" + stats_ml\n",
    "\n",
    "    if variable_name in ds_nwp_first_timestep:\n",
    "        stats_nwp = f\"NWP Model:\\nSkewness: {skew(data_nwp):.2f}\\nKurtosis: {kurtosis(data_nwp):.2f}\"\n",
    "        stats_text = stats_text + \"\\n\\n\" + stats_nwp\n",
    "\n",
    "    # Add text box\n",
    "    ax.text(\n",
    "        0.95,\n",
    "        0.55,\n",
    "        stats_text,\n",
    "        transform=ax.transAxes,\n",
    "        bbox=dict(alpha=0.8, facecolor=\"white\", edgecolor=\"black\"),\n",
    "        color=\"black\",\n",
    "        verticalalignment=\"bottom\",\n",
    "        horizontalalignment=\"right\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_plot(fig, f\"histogram_{variable_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dc37e",
   "metadata": {},
   "source": [
    "### 3. Energy Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edca0eb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "This chapter examines how energy is distributed across different spatial scales\n",
    "in the atmosphere by computing and comparing the energy spectra of both models.\n",
    "This analysis is critical in understanding the models' capabilities to simulate\n",
    "atmospheric processes ranging from large-scale weather systems to small-scale\n",
    "turbulence.\n",
    "\n",
    "**FFT Computation:** The Fast Fourier Transform (FFT) is used to transform spatial data into the frequency domain, revealing how different scales contribute to the overall energy. The energy spectra are averaged over latitudes.\n",
    "\n",
    "**Scale Representation:** The energy spectra show whether the ML model captures the correct amount of energy at various spatial scales.\n",
    "\n",
    "**Effective Resolution:** Identifying the effective resolution helps understand the smallest scales that the model can reliably simulate.\n",
    "\n",
    "**Numerical Artifacts:** Limitations in numerical precision can introduce artifacts in the spectra, especially at the smallest scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0be521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_spectra(data):\n",
    "    \"\"\"Calculate the energy spectra of the given data using 2D FFT.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : xarray.DataArray\n",
    "        The data for which the energy spectra should be calculated.\n",
    "        Expected dimensions: (x, y, time)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wavenumber : np.ndarray\n",
    "        The isotropic wavenumbers.\n",
    "    power : np.ndarray\n",
    "        The power spectrum averaged over time and azimuthally.\n",
    "    effective_resolution : float\n",
    "        The effective resolution of the model.\n",
    "    \"\"\"\n",
    "    # Get grid spacing in meters\n",
    "    dx = abs(float(data.x[1] - data.x[0]))\n",
    "    dy = abs(float(data.y[1] - data.y[0]))\n",
    "\n",
    "    # Transpose data to (time, y, x) for FFT\n",
    "    var_data = data.transpose(\"time\", \"y\", \"x\")\n",
    "\n",
    "    # Get dimensions\n",
    "    _, ny, nx = var_data.shape\n",
    "\n",
    "    # Compute 2D FFT for each time step\n",
    "    fft_data = np.fft.rfft2(var_data, axes=(-2, -1))  # (time, ky, kx)\n",
    "\n",
    "    # Calculate power spectrum\n",
    "    power_spectrum = np.abs(fft_data) ** 2\n",
    "\n",
    "    # Get wavenumbers\n",
    "    kx = np.fft.rfftfreq(nx, d=dx)  # x-direction wavenumbers\n",
    "    ky = np.fft.fftfreq(ny, d=dy)  # y-direction wavenumbers\n",
    "\n",
    "    # Create 2D wavenumber grid\n",
    "    kxx, kyy = np.meshgrid(kx, ky)\n",
    "    k_mag = np.sqrt(kxx**2 + kyy**2)  # Magnitude of wavenumber vector\n",
    "\n",
    "    # Create wavenumber bins for azimuthal averaging\n",
    "    k_bins = np.logspace(\n",
    "        np.log10(k_mag[k_mag > 0].min()), np.log10(k_mag.max()), num=50\n",
    "    )\n",
    "\n",
    "    # Average power spectrum over time\n",
    "    power_spectrum = power_spectrum.mean(axis=0)\n",
    "\n",
    "    # Perform azimuthal averaging\n",
    "    k_averaged = []\n",
    "    power_averaged = []\n",
    "\n",
    "    for i in range(len(k_bins) - 1):\n",
    "        k_mask = (k_mag >= k_bins[i]) & (k_mag < k_bins[i + 1])\n",
    "        if k_mask.any():\n",
    "            k_averaged.append(np.mean(k_mag[k_mask]))\n",
    "            power_averaged.append(np.mean(power_spectrum[k_mask]))\n",
    "\n",
    "    # Convert to arrays\n",
    "    k_averaged = np.array(k_averaged)\n",
    "    power_averaged = np.array(power_averaged)\n",
    "\n",
    "    # Calculate effective resolution (wavelength corresponding to 4dx)\n",
    "    effective_resolution = 1 / (4 * dx)\n",
    "\n",
    "    # Remove first and last two wavenumbers\n",
    "    return (k_averaged[2:-2], power_averaged[2:-2], effective_resolution)\n",
    "\n",
    "\n",
    "def plot_energy_spectra(ds_gt, ds_nwp, ds_ml, var, level=None):\n",
    "    \"\"\"Plot energy spectra comparison with LSD metric.\"\"\"\n",
    "    if level is not None:\n",
    "        var_data = ds_gt[var].sel(z=level)\n",
    "        if var in ds_nwp:\n",
    "            var_data_nwp = ds_nwp[var].sel(z=level)\n",
    "        var_data_ml = ds_ml[var].sel(z=level)\n",
    "    else:\n",
    "        var_data = ds_gt[var]\n",
    "        if var in ds_nwp:\n",
    "            var_data_nwp = ds_nwp[var]\n",
    "        var_data_ml = ds_ml[var]\n",
    "\n",
    "    # Calculate energy spectra\n",
    "    wavenumber_gt, spectrum_gt, effective_resolution = calculate_energy_spectra(\n",
    "        var_data\n",
    "    )\n",
    "    if var in ds_nwp:\n",
    "        wavenumber_nwp, spectrum_nwp, _ = calculate_energy_spectra(var_data_nwp)\n",
    "    else:\n",
    "        spectrum_nwp = None\n",
    "    wavenumber_ml, spectrum_ml, _ = calculate_energy_spectra(var_data_ml)\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI)\n",
    "\n",
    "    # Plot spectra\n",
    "    ax.loglog(\n",
    "        wavenumber_gt,\n",
    "        spectrum_gt,\n",
    "        color=COLORS[\"ground_truth\"],\n",
    "        label=\"Ground Truth\",\n",
    "        linestyle=LINE_STYLES[\"ground_truth\"][0],\n",
    "        marker=LINE_STYLES[\"ground_truth\"][1],\n",
    "        markevery=5,\n",
    "    )  # Add markers every 5 points for clarity\n",
    "\n",
    "    if var in ds_nwp:\n",
    "        ax.loglog(\n",
    "            wavenumber_nwp,\n",
    "            spectrum_nwp,\n",
    "            color=COLORS[\"nwp\"],\n",
    "            label=\"NWP Model Prediction\",\n",
    "            linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "            marker=LINE_STYLES[\"nwp\"][1],\n",
    "            markevery=3,\n",
    "        )\n",
    "\n",
    "    ax.loglog(\n",
    "        wavenumber_ml,\n",
    "        spectrum_ml,\n",
    "        color=COLORS[\"ml\"],\n",
    "        label=\"ML Model Prediction\",\n",
    "        linestyle=LINE_STYLES[\"ml\"][0],\n",
    "        marker=LINE_STYLES[\"ml\"][1],\n",
    "        markevery=4,\n",
    "    )\n",
    "\n",
    "    # Plot effective resolution\n",
    "    ax.axvline(\n",
    "        effective_resolution,\n",
    "        color=\"salmon\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"Effective Model Resolution\",\n",
    "    )\n",
    "\n",
    "    # Add LSD metric\n",
    "    add_lsd_to_plot(ax, spectrum_gt, spectrum_nwp, spectrum_ml)\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Wavenumber [1/m]\")\n",
    "    unit = VARIABLE_UNITS.get(var, \"\")\n",
    "    ax.set_ylabel(f\"Power Spectral Density [{unit}²/m]\")\n",
    "    title = f\"Energy Spectra Comparison for {var}\"\n",
    "    if level is not None:\n",
    "        title += f\" at Level {level} hPa\"\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "\n",
    "    # Save plot\n",
    "    plot_name = f\"energy_spectra_{var}\"\n",
    "    if level is not None:\n",
    "        plot_name += f\"_level_{level}\"\n",
    "    save_plot(fig, plot_name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def calculate_log_spectral_distance(true_spectrum, nwp_spectrum, ml_spectrum):\n",
    "    \"\"\"\n",
    "    Calculate the Log Spectral Distance between three power spectra\n",
    "    \"\"\"\n",
    "    eps = 1e-10\n",
    "    log_spec1 = np.log10(true_spectrum + eps)\n",
    "    log_spec3 = np.log10(ml_spectrum + eps)\n",
    "    lsd_ml = np.sqrt(np.mean((log_spec1 - log_spec3) ** 2))\n",
    "    if nwp_spectrum is None:\n",
    "        return None, lsd_ml\n",
    "    log_spec2 = np.log10(nwp_spectrum + eps)\n",
    "    lsd_nwp = np.sqrt(np.mean((log_spec1 - log_spec2) ** 2))\n",
    "    return lsd_nwp, lsd_ml\n",
    "\n",
    "\n",
    "def add_lsd_to_plot(ax, true_spectrum, nwp_spectrum, ml_spectrum):\n",
    "    \"\"\"\n",
    "    Add LSD metric as text box to spectrum plot\n",
    "    \"\"\"\n",
    "    if nwp_spectrum is None:\n",
    "        lsd_nwp = None\n",
    "        _, lsd_ml = calculate_log_spectral_distance(\n",
    "            true_spectrum, None, ml_spectrum\n",
    "        )\n",
    "        textstr = f\"LSD ML = {lsd_ml:.4f}\"\n",
    "    else:\n",
    "        lsd_nwp, lsd_ml = calculate_log_spectral_distance(\n",
    "            true_spectrum, nwp_spectrum, ml_spectrum\n",
    "        )\n",
    "        textstr = f\"LSD NWP = {lsd_nwp:.4f}, LSD ML = {lsd_ml:.4f}\"\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "    ax.text(\n",
    "        0.4,\n",
    "        0.05,\n",
    "        textstr,\n",
    "        transform=ax.transAxes,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=props,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e005e9",
   "metadata": {},
   "source": [
    "To interpret the Log-Spectral Distance (LSD) metric:\n",
    "The LSD quantifies the difference between two spectra, with lower values indicating better similarity (area between the two spectra). \n",
    "\n",
    "Lower values indicate better similarity between spectra\n",
    "- LSD = 0 means identical spectra\n",
    "\n",
    "Typical values depend on the specific application, but generally:\n",
    "- LSD < 1: Good similarity\n",
    "- 1 < LSD < 2: Moderate differences\n",
    "- LSD > 2: Significant differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2D variables\n",
    "for var in VARIABLES_GROUND_TRUTH.values():\n",
    "    fig, ax = plot_energy_spectra(\n",
    "        ds_gt, ds_nwp_first_timestep, ds_ml_first_timestep, var\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_and_export_lsd_table(\n",
    "    ds_gt, ds_ml, ds_nwp, variables, name, caption=\"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Display and export a table with LSD metrics for variables as rows and ML/NWP as columns.\n",
    "\n",
    "    Args:\n",
    "        ds_gt, ds_ml, ds_nwp: Input datasets\n",
    "        variables: Variables to analyze\n",
    "        name: Name for the exported files\n",
    "        caption: Caption for the LaTeX table\n",
    "    \"\"\"\n",
    "    # Initialize data dictionary with ML and NWP columns\n",
    "    lsd_data = {var: {\"ML\": None, \"NWP\": None} for var in variables}\n",
    "\n",
    "    for var in variables:\n",
    "        var_data_gt = ds_gt[var]\n",
    "        var_data_ml = ds_ml[var]\n",
    "\n",
    "        # Calculate ML metrics\n",
    "        _, spectrum_gt, _ = calculate_energy_spectra(var_data_gt)\n",
    "        _, spectrum_ml, _ = calculate_energy_spectra(var_data_ml)\n",
    "        _, lsd_ml = calculate_log_spectral_distance(\n",
    "            spectrum_gt, None, spectrum_ml\n",
    "        )\n",
    "        lsd_data[var][\"ML\"] = lsd_ml\n",
    "\n",
    "        # Calculate NWP metrics if variable exists in NWP data\n",
    "        if var in ds_nwp:\n",
    "            var_data_nwp = ds_nwp[var]\n",
    "            _, spectrum_nwp, _ = calculate_energy_spectra(var_data_nwp)\n",
    "            _, lsd_nwp = calculate_log_spectral_distance(\n",
    "                spectrum_gt, None, spectrum_nwp\n",
    "            )\n",
    "            lsd_data[var][\"NWP\"] = lsd_nwp\n",
    "\n",
    "    df = pd.DataFrame(lsd_data).T\n",
    "\n",
    "    # Display styled table\n",
    "    styled_df = df.style.format(\n",
    "        lambda x: f\"{x:.3f}\" if pd.notnull(x) else \"-\"\n",
    "    ).map(\n",
    "        lambda x: f\"color: {'green' if x < 1 else 'orange' if x < 2 else 'red'}\"\n",
    "        if pd.notnull(x)\n",
    "        else \"\"\n",
    "    )\n",
    "    display(styled_df)\n",
    "\n",
    "    # Export raw dataframe\n",
    "    export_table(df, name, caption)\n",
    "\n",
    "\n",
    "display_and_export_lsd_table(\n",
    "    ds_gt_first_timestep,\n",
    "    ds_ml_first_timestep,\n",
    "    ds_nwp_first_timestep,\n",
    "    VARIABLES_GROUND_TRUTH.values(),\n",
    "    name=\"lsd_metrics\",\n",
    "    caption=\"Log Spectral Distance (LSD) metrics comparison between ML and NWP models\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b36745",
   "metadata": {},
   "source": [
    "### 4. Vertical Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897b6fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In this chapter, the focus is on assessing how the relative error between the ML\n",
    "model and ground truth data.\n",
    "Vertical profiles are essential for understanding the atmospheric structure and\n",
    "processes at different pressure levels. Obviously these plots only work for 3D\n",
    "variables.\n",
    "\n",
    "**Relative Error Calculation:** Using percentage differences provides a\n",
    "normalized measure of error that is comparable across variables and vertical\n",
    "levels.\n",
    "\n",
    "**Altitude-Specific Insights:** The plots reveal whether the ML model performs\n",
    "consistently across different altitudes or if certain layers pose challenges.\n",
    "\n",
    "**Atmospheric Dynamics:** Accurate representation of vertical profiles is\n",
    "crucial for modeling phenomena like convection or jet stream anomalies.\n",
    "\n",
    "**Pressure Level Interpretation:** Lower vertical levels correspond to higher\n",
    "altitudes. Inverted axes help represent this correctly but can be\n",
    "counterintuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertical_errors_multigrid(ds_gt, ds_ml, variables):\n",
    "    \"\"\"\n",
    "    Plot vertical profiles of relative error for multiple variables in a grid.\n",
    "    Variables with same prefix are stacked along level dimension.\n",
    "    \"\"\"\n",
    "    # Group variables by their prefix (without level)\n",
    "    var_groups = {}\n",
    "    for var in variables.values():\n",
    "        if any(var.startswith(v) for v in VARIABLES_3D):\n",
    "            # Extract base name (without level) and level number\n",
    "            base_name = \"_\".join(var.split(\"_\")[:-2])  # Remove 'level_XX'\n",
    "            level = int(var.split(\"_\")[-1])\n",
    "\n",
    "            if base_name not in var_groups:\n",
    "                var_groups[base_name] = {\"vars\": [], \"levels\": []}\n",
    "            var_groups[base_name][\"vars\"].append(var)\n",
    "            var_groups[base_name][\"levels\"].append(level)\n",
    "            var_groups[base_name][\"unit\"] = VARIABLE_UNITS[var]\n",
    "\n",
    "    assert len(var_groups) > 0, \"No 3D variables found in the dataset\"\n",
    "\n",
    "    # Stack variables for each dataset\n",
    "    stacked_ds_gt = {}\n",
    "    stacked_ds_ml = {}\n",
    "\n",
    "    for base_name, group in var_groups.items():\n",
    "        # Sort by level to ensure correct ordering\n",
    "        sorted_idx = np.argsort(group[\"levels\"])\n",
    "        sorted_vars = [group[\"vars\"][i] for i in sorted_idx]\n",
    "        sorted_levels = [group[\"levels\"][i] for i in sorted_idx]\n",
    "\n",
    "        # Stack along new level dimension\n",
    "        stacked_ds_gt[base_name] = xr.concat(\n",
    "            [ds_gt[var] for var in sorted_vars],\n",
    "            dim=pd.Index(sorted_levels, name=\"level\"),\n",
    "        )\n",
    "        stacked_ds_ml[base_name] = xr.concat(\n",
    "            [ds_ml[var] for var in sorted_vars],\n",
    "            dim=pd.Index(sorted_levels, name=\"level\"),\n",
    "        )\n",
    "\n",
    "    # Plot stacked variables\n",
    "    num_vars = len(var_groups)\n",
    "    cols = 2\n",
    "    rows = (num_vars + 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows), dpi=DPI)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for i, (base_name, _) in enumerate(var_groups.items()):\n",
    "        relative_error_ml = (\n",
    "            abs(stacked_ds_ml[base_name] - stacked_ds_gt[base_name])\n",
    "            / abs(stacked_ds_gt[base_name] + epsilon)\n",
    "        ).mean(dim=[\"time\", \"y\", \"x\"]) * 100\n",
    "\n",
    "        # Plot vertical profile\n",
    "        axes[i].plot(\n",
    "            relative_error_ml,\n",
    "            relative_error_ml.level,\n",
    "            color=COLORS[\"ml\"],\n",
    "            linestyle=LINE_STYLES[\"ml\"][0],\n",
    "            marker=LINE_STYLES[\"ml\"][1],\n",
    "            linewidth=2,\n",
    "            label=\"ML Model\",\n",
    "        )\n",
    "        unit = var_groups[base_name][\"unit\"][0]\n",
    "        axes[i].set_title(f\"Relative Error for {base_name} [{unit}]\", size=12)\n",
    "        axes[i].set_xlabel(\"Relative Error (%)\", size=10)\n",
    "        axes[i].set_ylabel(\"Level\", size=10)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].invert_yaxis()\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Save plot\n",
    "    save_plot(fig, f\"vertical_profile_{base_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return (\n",
    "        stacked_ds_gt,\n",
    "        stacked_ds_ml,\n",
    "    )  # Return stacked datasets for further use\n",
    "\n",
    "\n",
    "stacked_gt, stacked_ml = plot_vertical_errors_multigrid(\n",
    "    ds_gt_first_timestep, ds_ml_first_timestep, VARIABLES_GROUND_TRUTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31acd86a",
   "metadata": {},
   "source": [
    "### 5. Various Verification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b338bf",
   "metadata": {},
   "source": [
    "The final chapter consolidates various statistical metrics to provide a broad\n",
    "evaluation of the ML model's performance. By considering multiple metrics, we\n",
    "gain a nuanced understanding of both the strengths and weaknesses of the model.\n",
    "\n",
    "**Metric Diversity:** Including MAE, RMSE, MSE, Pearson correlation, and the\n",
    "Fractions Skill Score (FSS) covers different aspects of model performance, from\n",
    "average errors to spatial pattern accuracy.\n",
    "\n",
    "**MAE, MSE and RMSE:** Offer insights into the average magnitude of errors, with\n",
    "RMSE emphasizing larger discrepancies. The colors indicating high errors are\n",
    "only implemented for these three metrics with standardization.\n",
    "\n",
    "**Pearson Correlation:** Assesses the linear relationship, indicating whether\n",
    "the model captures variability even if biases exist.\n",
    "\n",
    "**FSS:** Evaluates spatial accuracy, which is particularly important for\n",
    "predicting localized weather events.\n",
    "\n",
    "**Wasserstein Distance:** Provides a holistic view of distributional similarity\n",
    "across variables. Same as chapter 3.\n",
    "\n",
    "**Holistic Assessment:** The combination of metrics provides a comprehensive\n",
    "performance profile, essential for model validation and comparison. More complex metrics are explained in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca95bd3",
   "metadata": {},
   "source": [
    "#### Fractional Skill Score\n",
    "Range: 0 to 1, where:\n",
    "- 1 = perfect score\n",
    "- 0 = no skill compared to random chance\n",
    "\n",
    "**Key Properties:**\n",
    "- FSS measures the spatial agreement between two fields, accounting for the spatial scale of the features\n",
    "- It's particularly useful for assessing the spatial distribution of precipitation, cloud cover, or other fields with spatial structure\n",
    "\n",
    "**Advantages:**\n",
    "- More meaningful than simple correlation for spatial fields\n",
    "- Accounts for the spatial scale of features\n",
    "- Provides a single value for the entire field comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These helper functions are only used to calculate the FSS threshold\n",
    "max_spatial_dim = np.maximum(ds_gt.x.size, ds_gt.y.size)\n",
    "window_size = (max_spatial_dim // 100,) * 2\n",
    "n_points = int(\n",
    "    np.minimum(\n",
    "        SUBSAMPLE_FSS_THRESHOLD,\n",
    "        ds_ml[list(VARIABLES_GROUND_TRUTH.values())[0]]\n",
    "        .isel(elapsed_forecast_duration=0)\n",
    "        .size,\n",
    "    )\n",
    ")\n",
    "print(f\"Using window size for FSS: {window_size}\")\n",
    "print(f\"Using n_points for FSS: {n_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993f9ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def calculate_all_metrics(ds_gt, ds_nwp, ds_ml, metrics_to_compute=None):\n",
    "    \"\"\"Calculate a set of metrics for each variable in the given datasets.\n",
    "\n",
    "    Args:\n",
    "        ds_gt: Ground truth dataset\n",
    "        ds_nwp: NWP predictions (optional)\n",
    "        ds_ml: ML model predictions\n",
    "        metrics_to_compute: List of metrics to compute (default: all metrics)\n",
    "            Options: ['MAE', 'RMSE', 'MSE', 'RelativeMAE', 'RelativeLRMSE',\n",
    "                     'PearsonR', 'FSS', 'Wasserstein']\n",
    "    \"\"\"\n",
    "    if metrics_to_compute is None:\n",
    "        metrics_to_compute = [\n",
    "            \"MAE\",\n",
    "            \"RMSE\",\n",
    "            \"MSE\",\n",
    "            \"RelativeMAE\",\n",
    "            \"RelativeRMSE\",\n",
    "            \"PearsonR\",\n",
    "            \"FSS\",\n",
    "            \"Wasserstein\",\n",
    "        ]\n",
    "\n",
    "    variables = list(ds_gt.data_vars)\n",
    "    metrics_dict = {}\n",
    "\n",
    "    def get_base_metrics(\n",
    "        var,\n",
    "        y_true,\n",
    "        y_pred_ml,\n",
    "        quantile_90,\n",
    "    ):\n",
    "        base_dict = {}\n",
    "\n",
    "        if \"MAE\" in metrics_to_compute:\n",
    "            base_dict[\"MAE ML\"] = mae(y_true, y_pred_ml).values\n",
    "        if \"RMSE\" in metrics_to_compute:\n",
    "            base_dict[\"RMSE ML\"] = rmse(y_true, y_pred_ml).values\n",
    "        if \"MSE\" in metrics_to_compute:\n",
    "            base_dict[\"MSE ML\"] = mse(y_true, y_pred_ml).values\n",
    "        if \"RelativeMAE\" in metrics_to_compute:\n",
    "            base_dict[\"Relative MAE ML\"] = np.mean(\n",
    "                np.abs(y_true.values - y_pred_ml.values)\n",
    "                / (np.abs(y_true.values) + 1e-6)\n",
    "            )\n",
    "        if \"RelativeRMSE\" in metrics_to_compute:\n",
    "            base_dict[\"Relative RMSE ML\"] = np.sqrt(\n",
    "                np.mean(\n",
    "                    (y_true.values - y_pred_ml.values) ** 2\n",
    "                    / (y_true.values**2 + 1e-6)\n",
    "                )\n",
    "            )\n",
    "        if \"PearsonR\" in metrics_to_compute:\n",
    "            base_dict[\"Pearson R ML\"] = pearsonr(y_true, y_pred_ml).values\n",
    "        if \"FSS\" in metrics_to_compute:\n",
    "            base_dict[\"FSS ML\"] = fss_2d(\n",
    "                y_pred_ml,\n",
    "                y_true,\n",
    "                event_threshold=quantile_90,\n",
    "                window_size=window_size,\n",
    "                spatial_dims=[\"y\", \"x\"],\n",
    "            ).values\n",
    "        if \"Wasserstein\" in metrics_to_compute:\n",
    "            base_dict[\"Wasserstein ML\"] = wasserstein_distance(\n",
    "                y_true.values.flatten(), y_pred_ml.values.flatten()\n",
    "            )\n",
    "\n",
    "        return base_dict\n",
    "\n",
    "    for var in variables:\n",
    "        print(f\"Calculating metrics for variable: {var}\")\n",
    "        y_true = ds_gt[var].compute()\n",
    "        y_pred_ml = ds_ml[var].compute()\n",
    "\n",
    "        sample = np.random.choice(\n",
    "            y_true.values.ravel(), n_points, replace=False\n",
    "        )\n",
    "        quantile_90 = np.quantile(sample, 0.90)\n",
    "\n",
    "        metrics_dict[var] = get_base_metrics(\n",
    "            var, y_true, y_pred_ml, quantile_90\n",
    "        )\n",
    "\n",
    "        if ds_nwp is not None and var in ds_nwp:\n",
    "            y_pred_nwp = ds_nwp[var].compute()\n",
    "            nwp_metrics = {}\n",
    "\n",
    "            if \"MAE\" in metrics_to_compute:\n",
    "                nwp_metrics[\"MAE NWP\"] = mae(y_true, y_pred_nwp).values\n",
    "            if \"RMSE\" in metrics_to_compute:\n",
    "                nwp_metrics[\"RMSE NWP\"] = rmse(y_true, y_pred_nwp).values\n",
    "            if \"MSE\" in metrics_to_compute:\n",
    "                nwp_metrics[\"MSE NWP\"] = mse(y_true, y_pred_nwp).values\n",
    "            if \"RelativeMAE\" in metrics_to_compute:\n",
    "                nwp_metrics[\"Relative MAE ML\"] = np.mean(\n",
    "                    np.abs(y_true.values - y_pred_ml.values)\n",
    "                    / (np.abs(y_true.values) + 1e-6)\n",
    "                )\n",
    "            if \"RelativeRMSE\" in metrics_to_compute:\n",
    "                nwp_metrics[\"Relative RMSE ML\"] = np.sqrt(\n",
    "                    np.mean(\n",
    "                        (y_true.values - y_pred_ml.values) ** 2\n",
    "                        / (y_true.values**2 + 1e-6)\n",
    "                    )\n",
    "                )\n",
    "            if \"PearsonR\" in metrics_to_compute:\n",
    "                nwp_metrics[\"Pearson R NWP\"] = pearsonr(\n",
    "                    y_true, y_pred_nwp\n",
    "                ).values\n",
    "            if \"FSS\" in metrics_to_compute:\n",
    "                nwp_metrics[\"FSS NWP\"] = fss_2d(\n",
    "                    y_pred_nwp,\n",
    "                    y_true,\n",
    "                    event_threshold=quantile_90,\n",
    "                    window_size=window_size,\n",
    "                    spatial_dims=[\"y\", \"x\"],\n",
    "                ).values\n",
    "            if \"Wasserstein\" in metrics_to_compute:\n",
    "                nwp_metrics[\"Wasserstein NWP\"] = wasserstein_distance(\n",
    "                    y_true.values.flatten(), y_pred_nwp.values.flatten()\n",
    "                )\n",
    "\n",
    "            metrics_dict[var].update(nwp_metrics)\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics_dict, orient=\"index\")\n",
    "\n",
    "    export_table(\n",
    "        metrics_df,\n",
    "        \"verification_metrics\",\n",
    "        caption=\"Performance metrics for ML model predictions\",\n",
    "    )\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def get_formatters(has_nwp=True):\n",
    "    base_formatters = {\n",
    "        \"MAE ML\": \"{:.4f}\",\n",
    "        \"RMSE ML\": \"{:.4f}\",\n",
    "        \"MSE ML\": \"{:.4f}\",\n",
    "        \"Relative MAE ML\": \"{:.4f}\",\n",
    "        \"Relative RMSE ML\": \"{:.3e}\",\n",
    "        \"Pearson R ML\": \"{:.4f}\",\n",
    "        \"FSS ML\": \"{:.4f}\",\n",
    "        \"Wasserstein ML\": \"{:.4f}\",\n",
    "    }\n",
    "\n",
    "    if has_nwp:\n",
    "        base_formatters.update({\n",
    "            \"MAE NWP\": \"{:.4f}\",\n",
    "            \"RMSE NWP\": \"{:.4f}\",\n",
    "            \"MSE NWP\": \"{:.4f}\",\n",
    "            \"Relative MAE NWP\": \"{:.4f}\",\n",
    "            \"Relative RMSE NWP\": \"{:.3e}\",\n",
    "            \"Pearson R NWP\": \"{:.4f}\",\n",
    "            \"FSS NWP\": \"{:.4f}\",\n",
    "            \"Wasserstein NWP\": \"{:.4f}\",\n",
    "        })\n",
    "\n",
    "    return base_formatters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and run Dask cluster for NWP-variables\n",
    "with LocalCluster(\n",
    "    n_workers=32, threads_per_worker=1, memory_limit=\"8GB\"\n",
    ") as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        print(f\"Dask dashboard available at: {client.dashboard_link}\")\n",
    "\n",
    "        # Calculate metrics\n",
    "        regular_metrics = calculate_all_metrics(\n",
    "            ds_gt_first_timestep[list(VARIABLES_NWP.values())],\n",
    "            ds_nwp_first_timestep[list(VARIABLES_NWP.values())],\n",
    "            ds_ml_first_timestep[list(VARIABLES_NWP.values())],\n",
    "            metrics_to_compute=[\n",
    "                \"MAE\",\n",
    "                \"RMSE\",\n",
    "                # \"MSE\",\n",
    "                \"RelativeMAE\",\n",
    "                \"RelativeRMSE\",\n",
    "                \"PearsonR\",\n",
    "                \"FSS\",\n",
    "                # \"Wasserstein\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "        print(\"Regular Metrics:\")\n",
    "        display(regular_metrics.style.format(get_formatters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106501a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set up and run Dask cluster for variables not in NWP\n",
    "with LocalCluster(\n",
    "    n_workers=32, threads_per_worker=1, memory_limit=\"8GB\"\n",
    ") as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        print(f\"Dask dashboard available at: {client.dashboard_link}\")\n",
    "\n",
    "        # Calculate metrics\n",
    "        regular_metrics = calculate_all_metrics(\n",
    "            ds_gt_first_timestep[\n",
    "                [\n",
    "                    var\n",
    "                    for var in VARIABLES_ML.values()\n",
    "                    if var not in VARIABLES_NWP.values()\n",
    "                ]\n",
    "            ],\n",
    "            None,\n",
    "            ds_ml_first_timestep[\n",
    "                [\n",
    "                    var\n",
    "                    for var in VARIABLES_ML.values()\n",
    "                    if var not in VARIABLES_NWP.values()\n",
    "                ]\n",
    "            ],\n",
    "            metrics_to_compute=[\n",
    "                \"MAE\",\n",
    "                \"RMSE\",\n",
    "                # \"MSE\",\n",
    "                \"RelativeMAE\",\n",
    "                \"RelativeRMSE\",\n",
    "                \"PearsonR\",\n",
    "                \"FSS\",\n",
    "                # \"Wasserstein\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "        print(\"Regular Metrics:\")\n",
    "        display(regular_metrics.style.format(get_formatters(has_nwp=False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e8286",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Equitable Skill Score (MeteoSwiss Modified Version)\n",
    "Range: 0 to 1, where:\n",
    "- 1 = perfect score\n",
    "- 0.5 = no skill compared to random chance\n",
    "- < 0.5 = worse than random chance\n",
    "\n",
    "**Key Properties:**\n",
    "- Modified ETS rescales the traditional ETS using: ETSrescaled = ETS/2 + 0.5\n",
    "- Measures how well predicted events correspond to observed events, accounting for hits due to random chance\n",
    "- Particularly useful for rare events (like precipitation above a high threshold)\n",
    "- More equitable than simple Threat Score by accounting for hits due to random chance\n",
    "\n",
    "**Advantages:**\n",
    "- More intuitive scale from 0 to 1 compared to traditional ETS\n",
    "- Reference point at 0.5 makes interpretation clearer\n",
    "- Penalizes both misses and false alarms\n",
    "- Accounts for random chance, making it more robust than basic threat scores\n",
    "- Maintains original ETS properties while providing more intuitive scaling\n",
    "\n",
    "#### Frequency Bias Index\n",
    "Range: 0 to infinity, where:\n",
    "- 1 = no bias\n",
    "- < 1 = underforecasting\n",
    "- > 1 = overforecasting\n",
    "\n",
    "**Key Properties:**\n",
    "- FBI measures the ratio of observed to forecasted events, indicating whether the model tends to over- or underforecast\n",
    "- It's particularly useful for understanding systematic biases in event frequency\n",
    "\n",
    "**Advantages:**\n",
    "- Provides a clear indication of over- or underforecasting\n",
    "- Easy to interpret: 1 indicates no bias, while values above or below 1 show the direction and magnitude of the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_thresholds = [0.1, 1, 5]  # mm/h\n",
    "wind_thresholds = [2.5, 5, 10]  # m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea758476",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set display options for all float values\n",
    "pd.set_option(\"display.float_format\", lambda x: \"{:.4f}\".format(x))\n",
    "\n",
    "\n",
    "def frequency_bias(obs, pred, threshold):\n",
    "    \"\"\"Calculate Frequency Bias Index (FBI) for binary events.\"\"\"\n",
    "    count_obs = np.sum(obs >= threshold)\n",
    "    count_pred = np.sum(pred >= threshold)\n",
    "    return count_pred / count_obs if count_obs > 0 else np.nan\n",
    "\n",
    "\n",
    "def mean_error(obs, pred):\n",
    "    \"\"\"Calculate mean error (ME) between prediction and observation.\"\"\"\n",
    "    return float(np.mean(pred - obs))\n",
    "\n",
    "\n",
    "def mean_absolute_error(obs, pred):\n",
    "    \"\"\"Calculate mean absolute error (MAE) between prediction and observation.\"\"\"\n",
    "    return float(np.mean(np.abs(pred - obs)))\n",
    "\n",
    "\n",
    "def ets_for_threshold(obs, pred, threshold):\n",
    "    \"\"\"Calculate ETS with MeteoSwiss rescaling (ETSrescaled = ETS/2 + 0.5).\"\"\"\n",
    "    if isinstance(obs, np.ndarray):\n",
    "        obs = xr.DataArray(obs)\n",
    "    if isinstance(pred, np.ndarray):\n",
    "        pred = xr.DataArray(pred)\n",
    "\n",
    "    # Convert to binary using threshold\n",
    "    f_binary = (pred > threshold).astype(int)\n",
    "    o_binary = (obs > threshold).astype(int)\n",
    "\n",
    "    try:\n",
    "        # Compute contingency table\n",
    "        hits = float(((f_binary == 1) & (o_binary == 1)).sum())\n",
    "        false_alarms = float(((f_binary == 1) & (o_binary == 0)).sum())\n",
    "        misses = float(((f_binary == 0) & (o_binary == 1)).sum())\n",
    "        correct_zeros = float(((f_binary == 0) & (o_binary == 0)).sum())\n",
    "\n",
    "        total = hits + false_alarms + misses + correct_zeros\n",
    "\n",
    "        # Calculate hits due to chance\n",
    "        hits_random = ((hits + false_alarms) * (hits + misses)) / total\n",
    "\n",
    "        # Calculate original ETS score\n",
    "        denominator = hits - hits_random + false_alarms + misses\n",
    "        if denominator == 0:\n",
    "            ets = 0.0 if total > 0 else 1.0\n",
    "        else:\n",
    "            ets = (hits - hits_random) / denominator\n",
    "\n",
    "        # Apply MeteoSwiss rescaling\n",
    "        ets_rescaled = ets / 2.0 + 0.5\n",
    "\n",
    "        return max(0.0, min(1.0, ets_rescaled))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing ETS: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def stdev_error(obs, pred):\n",
    "    \"\"\"Calculate standard deviation of error.\"\"\"\n",
    "    return abs(np.std(pred - obs))\n",
    "\n",
    "\n",
    "if \"precipitation\" in ds_gt_first_timestep:\n",
    "    # --- Group 1: Precipitation Metrics ---\n",
    "    results_precip = {}\n",
    "\n",
    "    y_true_all = ds_gt_first_timestep[\"precipitation\"].values\n",
    "    y_ml_all = ds_ml_first_timestep[\"precipitation\"].values\n",
    "    y_nwp_all = (\n",
    "        ds_nwp_first_timestep[\"precipitation\"].values\n",
    "        if \"precipitation\" in ds_nwp_first_timestep\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    for thr in precip_thresholds:\n",
    "        # Calculate masks\n",
    "        mask_ml = (y_true_all >= thr) | (y_ml_all >= thr)\n",
    "        mask_nwp = (\n",
    "            (y_true_all >= thr) | (y_nwp_all >= thr)\n",
    "            if y_nwp_all is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # Calculate ML metrics\n",
    "        mae_ml = mean_absolute_error(y_true_all, y_ml_all)\n",
    "        me_ml = mean_error(y_true_all, y_ml_all)\n",
    "        fbi_ml = frequency_bias(y_true_all, y_ml_all, thr)\n",
    "        ets_ml = (\n",
    "            ets_for_threshold(y_true_all[mask_ml], y_ml_all[mask_ml], thr)\n",
    "            if mask_ml.any()\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "        # Calculate NWP metrics\n",
    "        if y_nwp_all is not None:\n",
    "            mae_nwp = mean_absolute_error(y_true_all, y_nwp_all)\n",
    "            me_nwp = mean_error(y_true_all, y_nwp_all)\n",
    "            fbi_nwp = frequency_bias(y_true_all, y_nwp_all, thr)\n",
    "            ets_nwp = (\n",
    "                ets_for_threshold(\n",
    "                    y_true_all[mask_nwp], y_nwp_all[mask_nwp], thr\n",
    "                )\n",
    "                if mask_nwp.any()\n",
    "                else np.nan\n",
    "            )\n",
    "        else:\n",
    "            mae_nwp = me_nwp = fbi_nwp = ets_nwp = np.nan\n",
    "\n",
    "        results_precip[f\"{thr} mm/h\"] = {\n",
    "            \"MAE ML\": mae_ml,\n",
    "            \"ME ML\": me_ml,\n",
    "            \"FBI ML\": fbi_ml,\n",
    "            \"ETS ML\": ets_ml,\n",
    "            \"MAE NWP\": mae_nwp,\n",
    "            \"ME NWP\": me_nwp,\n",
    "            \"FBI NWP\": fbi_nwp,\n",
    "            \"ETS NWP\": ets_nwp,\n",
    "        }\n",
    "    # Convert DataFrames with explicit formatting\n",
    "    results_precip_df = pd.DataFrame(results_precip).T.round(4)\n",
    "    export_table(\n",
    "        results_precip_df,\n",
    "        \"precipitation_metrics\",\n",
    "        caption=\"Precipitation verification metrics for different thresholds\",\n",
    "    )\n",
    "    # Display results\n",
    "    print(\"Precipitation Metrics:\")\n",
    "    display(pd.DataFrame(results_precip).T)\n",
    "\n",
    "\n",
    "if (\n",
    "    \"wind_u_10m\" in ds_gt_first_timestep\n",
    "    and \"wind_v_10m\" in ds_gt_first_timestep\n",
    "):\n",
    "    # --- Group 2: Wind Metrics ---\n",
    "    results_wind = {}\n",
    "\n",
    "    for var in [\"wind_u_10m\", \"wind_v_10m\"]:\n",
    "        var_results = {}\n",
    "        y_true_all = ds_gt_first_timestep[var].values\n",
    "        y_ml_all = ds_ml_first_timestep[var].values\n",
    "        y_nwp_all = (\n",
    "            ds_nwp_first_timestep[var].values\n",
    "            if var in ds_nwp_first_timestep\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        for thr in wind_thresholds:\n",
    "            # Calculate masks\n",
    "            mask_ml = (y_true_all >= thr) | (y_ml_all >= thr)\n",
    "            mask_nwp = (\n",
    "                (y_true_all >= thr) | (y_nwp_all >= thr)\n",
    "                if y_nwp_all is not None\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            # Calculate ML metrics\n",
    "            mae_ml = mean_absolute_error(y_true_all, y_ml_all)\n",
    "            me_ml = mean_error(y_true_all, y_ml_all)\n",
    "            fbi_ml = frequency_bias(y_true_all, y_ml_all, thr)\n",
    "            ets_ml = (\n",
    "                ets_for_threshold(y_true_all[mask_ml], y_ml_all[mask_ml], thr)\n",
    "                if mask_ml.any()\n",
    "                else np.nan\n",
    "            )\n",
    "\n",
    "            # Calculate NWP metrics\n",
    "            if y_nwp_all is not None:\n",
    "                mae_nwp = mean_absolute_error(y_true_all, y_nwp_all)\n",
    "                me_nwp = mean_error(y_true_all, y_nwp_all)\n",
    "                fbi_nwp = frequency_bias(y_true_all, y_nwp_all, thr)\n",
    "                ets_nwp = (\n",
    "                    ets_for_threshold(\n",
    "                        y_true_all[mask_nwp], y_nwp_all[mask_nwp], thr\n",
    "                    )\n",
    "                    if mask_nwp.any()\n",
    "                    else np.nan\n",
    "                )\n",
    "            else:\n",
    "                mae_nwp = me_nwp = fbi_nwp = ets_nwp = np.nan\n",
    "\n",
    "            var_results[f\"{thr} m/s\"] = {\n",
    "                \"MAE ML\": mae_ml,\n",
    "                \"ME ML\": me_ml,\n",
    "                \"FBI ML\": fbi_ml,\n",
    "                \"ETS ML\": ets_ml,\n",
    "                \"MAE NWP\": mae_nwp,\n",
    "                \"ME NWP\": me_nwp,\n",
    "                \"FBI NWP\": fbi_nwp,\n",
    "                \"ETS NWP\": ets_nwp,\n",
    "            }\n",
    "        results_wind[var] = var_results\n",
    "\n",
    "    results_wind_dfs = {\n",
    "        var: pd.DataFrame(metrics).T.round(4)\n",
    "        for var, metrics in results_wind.items()\n",
    "    }\n",
    "\n",
    "    for var, metrics in results_wind.items():\n",
    "        export_table(\n",
    "            pd.DataFrame(metrics).T,\n",
    "            f\"wind_metrics_{var}\",\n",
    "            caption=f\"Wind verification metrics for {var} at different thresholds\",\n",
    "        )\n",
    "        print(f\"\\nWind Metrics for {var}:\")\n",
    "        display(pd.DataFrame(metrics).T)\n",
    "\n",
    "if (\n",
    "    \"surface_net_shortwave_radiation\" in ds_gt_first_timestep\n",
    "    and \"temperature_2m\" in ds_gt_first_timestep\n",
    "    and \"surface_net_longwave_radiation\" in ds_gt_first_timestep\n",
    "):\n",
    "    # --- Group 3: Radiation and Temperature Metrics ---\n",
    "    vars_stdev = [\n",
    "        \"surface_net_shortwave_radiation\",\n",
    "        \"surface_net_longwave_radiation\",\n",
    "        \"temperature_2m\",\n",
    "    ]\n",
    "    results_stdev = {}\n",
    "\n",
    "    for var in vars_stdev:\n",
    "        y_true = ds_gt_first_timestep[var].values\n",
    "        y_ml = ds_ml_first_timestep[var].values\n",
    "        y_nwp = (\n",
    "            ds_nwp_first_timestep[var].values\n",
    "            if var in ds_nwp_first_timestep\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # Calculate ML metrics\n",
    "        mae_ml = mean_absolute_error(y_true, y_ml)\n",
    "        me_ml = mean_error(y_true, y_ml)\n",
    "        stdev_ml = stdev_error(y_true, y_ml)\n",
    "\n",
    "        # Calculate NWP metrics\n",
    "        if y_nwp is not None:\n",
    "            mae_nwp = mean_absolute_error(y_true, y_nwp)\n",
    "            me_nwp = mean_error(y_true, y_nwp)\n",
    "            stdev_nwp = stdev_error(y_true, y_nwp)\n",
    "        else:\n",
    "            mae_nwp = me_nwp = stdev_nwp = np.nan\n",
    "\n",
    "        results_stdev[var] = {\n",
    "            \"MAE ML\": mae_ml,\n",
    "            \"ME ML\": me_ml,\n",
    "            \"STDEV-ERR ML\": stdev_ml,\n",
    "            \"MAE NWP\": mae_nwp,\n",
    "            \"ME NWP\": me_nwp,\n",
    "            \"STDEV-ERR NWP\": stdev_nwp,\n",
    "        }\n",
    "\n",
    "    results_stdev_df = pd.DataFrame(results_stdev).T.round(4)\n",
    "    print(\"\\nMAE and STDEV Error Metrics for ASOB, ATHB, t_2m:\")\n",
    "    display(results_stdev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_vector_rmse(u_true, v_true, u_pred, v_pred):\n",
    "    \"\"\"Calculate RMSE based on wind vector differences.\"\"\"\n",
    "    rmse_u = rmse(u_true, u_pred)\n",
    "    rmse_v = rmse(v_true, v_pred)\n",
    "\n",
    "    # Calculate vector RMSE\n",
    "    rmse_wind = np.sqrt(rmse_u**2 + rmse_v**2)\n",
    "\n",
    "    return float(rmse_wind)\n",
    "\n",
    "\n",
    "if (\n",
    "    \"wind_u_10m\" in ds_gt_first_timestep\n",
    "    and \"wind_v_10m\" in ds_gt_first_timestep\n",
    "):\n",
    "    # Get both components for ML and ground truth\n",
    "    u_true = ds_gt_first_timestep[\"wind_u_10m\"]\n",
    "    v_true = ds_gt_first_timestep[\"wind_v_10m\"]\n",
    "    u_ml = ds_ml_first_timestep[\"wind_u_10m\"]\n",
    "    v_ml = ds_ml_first_timestep[\"wind_v_10m\"]\n",
    "\n",
    "    # Calculate vector RMSE for ML\n",
    "    wind_rmse_ml = wind_vector_rmse(u_true, v_true, u_ml, v_ml)\n",
    "\n",
    "    # Calculate for NWP if available\n",
    "    if (\n",
    "        \"wind_u_10m\" in ds_nwp_first_timestep\n",
    "        and \"wind_v_10m\" in ds_nwp_first_timestep\n",
    "    ):\n",
    "        u_nwp = ds_nwp_first_timestep[\"wind_u_10m\"]\n",
    "        v_nwp = ds_nwp_first_timestep[\"wind_v_10m\"]\n",
    "        wind_rmse_nwp = wind_vector_rmse(u_true, v_true, u_nwp, v_nwp)\n",
    "    else:\n",
    "        wind_rmse_nwp = np.nan\n",
    "\n",
    "    # Add to results\n",
    "    results_wind[\"vector_metrics\"] = {\n",
    "        \"RMSE ML\": wind_rmse_ml,\n",
    "        \"RMSE NWP\": wind_rmse_nwp,\n",
    "    }\n",
    "\n",
    "    # Create DataFrame for vector metrics\n",
    "    vector_metrics_df = pd.DataFrame(\n",
    "        results_wind[\"vector_metrics\"], index=[\"Value\"]\n",
    "    ).T.round(4)\n",
    "\n",
    "    # Export table\n",
    "    export_table(\n",
    "        vector_metrics_df,\n",
    "        \"wind_vector_metrics\",\n",
    "        caption=\"Wind vector RMSE metrics comparing ML and NWP predictions\",\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nWind Vector RMSE Metrics:\")\n",
    "    display(vector_metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b679ce5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Combined SAL = |S| + |A| + |L|\n",
    "- Range: [0 to 6]\n",
    "- 0: Perfect forecast\n",
    "- Higher values indicate worse forecasts\n",
    "\n",
    "1. Structure (S): [-2 to +2]\n",
    "- Measures how well the spatial patterns match\n",
    "- S = 0: Perfect structural agreement\n",
    "- S > 0: Predicted patterns too large/flat\n",
    "- S < 0: Predicted patterns too peaked/small\n",
    "\n",
    "2. Amplitude (A): [-2 to +2]\n",
    "- Measures the accuracy of domain-averaged values\n",
    "- A = 0: Perfect amplitude match\n",
    "- A > 0: Overestimation\n",
    "- A < 0: Underestimation\n",
    "\n",
    "3. Location (L): [0 to +2]\n",
    "- Measures the accuracy of spatial placement\n",
    "- L = 0: Perfect location match\n",
    "- L increases with distance between predicted and observed centers of mass\n",
    "\n",
    "SAL works best for:\n",
    "- Fields with distinct objects/features\n",
    "- Variables that can form coherent structures\n",
    "- Fields with clear boundaries/gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sal(ds_gt, ds_nwp, ds_ml, thr_factor=0.067, thr_quantile=0.9):\n",
    "    \"\"\"Calculate SAL metrics for each variable and level in the given datasets.\"\"\"\n",
    "    sal_dict = {}\n",
    "    var = \"precipitation\"\n",
    "    if var not in ds_gt or var not in ds_nwp or var not in ds_ml:\n",
    "        raise ValueError(f\"Variable {var} not found in datasets.\")\n",
    "\n",
    "    structure_scores_nwp = []\n",
    "    amplitude_scores_nwp = []\n",
    "    location_scores_nwp = []\n",
    "    structure_scores_ml = []\n",
    "    amplitude_scores_ml = []\n",
    "    location_scores_ml = []\n",
    "\n",
    "    for t in range(len(ds_gt.time)):\n",
    "        y_true = ds_gt[var].isel(time=t).values\n",
    "        y_pred_nwp = ds_nwp[var].isel(time=t).values\n",
    "        y_pred_ml = ds_ml[var].isel(time=t).values\n",
    "\n",
    "        try:\n",
    "            sal_score_nwp = sal(\n",
    "                y_pred_nwp,\n",
    "                y_true,\n",
    "                thr_factor=thr_factor,\n",
    "                thr_quantile=thr_quantile,\n",
    "            )\n",
    "            sal_score_ml = sal(\n",
    "                y_pred_ml,\n",
    "                y_true,\n",
    "                thr_factor=thr_factor,\n",
    "                thr_quantile=thr_quantile,\n",
    "            )\n",
    "            structure_scores_nwp.append(sal_score_nwp[0])\n",
    "            amplitude_scores_nwp.append(sal_score_nwp[1])\n",
    "            location_scores_nwp.append(sal_score_nwp[2])\n",
    "            structure_scores_ml.append(sal_score_ml[0])\n",
    "            amplitude_scores_ml.append(sal_score_ml[1])\n",
    "            location_scores_ml.append(sal_score_ml[2])\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating SAL for {var} at time {t}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if structure_scores_nwp and structure_scores_ml:\n",
    "        structure_mean_nwp = np.nanmean(structure_scores_nwp)\n",
    "        amplitude_mean_nwp = np.nanmean(amplitude_scores_nwp)\n",
    "        location_mean_nwp = np.nanmean(location_scores_nwp)\n",
    "        combined_mean_nwp = (\n",
    "            np.abs(structure_mean_nwp)\n",
    "            + np.abs(amplitude_mean_nwp)\n",
    "            + np.abs(location_mean_nwp)\n",
    "        )\n",
    "\n",
    "        structure_mean_ml = np.nanmean(structure_scores_ml)\n",
    "        amplitude_mean_ml = np.nanmean(amplitude_scores_ml)\n",
    "        location_mean_ml = np.nanmean(location_scores_ml)\n",
    "        combined_mean_ml = (\n",
    "            np.abs(structure_mean_ml)\n",
    "            + np.abs(amplitude_mean_ml)\n",
    "            + np.abs(location_mean_ml)\n",
    "        )\n",
    "\n",
    "        sal_dict[var] = {\n",
    "            \"Structure\": {\n",
    "                \"NWP\": structure_mean_nwp,\n",
    "                \"ML\": structure_mean_ml,\n",
    "            },\n",
    "            \"Amplitude\": {\n",
    "                \"NWP\": amplitude_mean_nwp,\n",
    "                \"ML\": amplitude_mean_ml,\n",
    "            },\n",
    "            \"Location\": {\"NWP\": location_mean_nwp, \"ML\": location_mean_ml},\n",
    "            \"Combined\": {\"NWP\": combined_mean_nwp, \"ML\": combined_mean_ml},\n",
    "        }\n",
    "\n",
    "    # Create multi-level DataFrame\n",
    "    df_dict = {}\n",
    "    for var in sal_dict:\n",
    "        for metric in sal_dict[var]:\n",
    "            df_dict[(var, metric, \"NWP\")] = sal_dict[var][metric][\"NWP\"]\n",
    "            df_dict[(var, metric, \"ML\")] = sal_dict[var][metric][\"ML\"]\n",
    "\n",
    "    df = pd.DataFrame(df_dict, index=[\"Value\"]).T\n",
    "    df = df.unstack(level=2)\n",
    "    df.columns = df.columns.droplevel(0)  # Remove 'Value' level\n",
    "\n",
    "    export_table(\n",
    "        df,\n",
    "        \"sal_metrics\",\n",
    "        caption=\"SAL metrics for precipitation prediction\",\n",
    "    )\n",
    "    formatters = {col: \"{:.4f}\" for col in df.columns}\n",
    "\n",
    "    return df.style.format(formatters)\n",
    "\n",
    "\n",
    "if \"precipitation\" in ds_gt:\n",
    "    sal_metrics = calculate_sal(\n",
    "        ds_gt_first_timestep, ds_nwp_first_timestep, ds_ml_first_timestep\n",
    "    )\n",
    "    display(sal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ae899",
   "metadata": {},
   "source": [
    "### 5.2 Time Series Across Elapsed_Forecast_Dimension\n",
    "\n",
    "This chapter provides a detailed view of how the ML model and NWP model evolve\n",
    "over time. By comparing time series data, we can identify when and where the\n",
    "models diverge, offering insights into the underlying causes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These helper functions are only used to calculate the FSS threshold\n",
    "max_spatial_dim = np.maximum(ds_gt.x.size, ds_gt.y.size)\n",
    "window_size = (max_spatial_dim // 100,) * 2\n",
    "n_points = int(\n",
    "    np.minimum(\n",
    "        SUBSAMPLE_FSS_THRESHOLD,\n",
    "        ds_ml[list(VARIABLES_GROUND_TRUTH.values())[0]]\n",
    "        .isel(elapsed_forecast_duration=0)\n",
    "        .size,\n",
    "    )\n",
    ")\n",
    "print(f\"Using window size for FSS: {window_size}\")\n",
    "print(f\"Using n_points for FSS: {n_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_thresholds = [0.1, 1, 5]  # mm/h\n",
    "wind_thresholds = [2.5, 5, 10]  # m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94994468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_over_leadtimes(\n",
    "    ds_gt,\n",
    "    ds_nwp,\n",
    "    ds_ml,\n",
    "    elapsed_forecast_durations,\n",
    "    variables,\n",
    "    metrics_to_compute,\n",
    "):\n",
    "    \"\"\"Calculate metrics for each elapsed forecast duration and variable.\"\"\"\n",
    "    metrics_by_leadtime = {}\n",
    "\n",
    "    for efd in elapsed_forecast_durations:\n",
    "        lt_hours = efd.astype(\"timedelta64[h]\").astype(int)\n",
    "        print(\n",
    "            f\"Calculating metrics for elapsed forecast duration {lt_hours} hours...\"\n",
    "        )\n",
    "        # Select data for current elapsed forecast duration\n",
    "        ds_ml_lead = ds_ml.sel(elapsed_forecast_duration=efd)\n",
    "        ds_nwp_lead = (\n",
    "            ds_nwp.sel(elapsed_forecast_duration=efd)\n",
    "            if ds_nwp is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = calculate_all_metrics(\n",
    "            ds_gt[variables].sel(time=ds_ml_lead.forecast_time),\n",
    "            ds_nwp_lead,\n",
    "            ds_ml_lead,\n",
    "            metrics_to_compute=metrics_to_compute,\n",
    "        )\n",
    "        metrics_by_leadtime[efd] = metrics\n",
    "\n",
    "    return metrics_by_leadtime\n",
    "\n",
    "\n",
    "def plot_metrics_over_leadtimes(\n",
    "    metrics_by_leadtime, elapsed_forecast_durations\n",
    "):\n",
    "    \"\"\"Create line plots showing how metrics evolve over elapsed forecast durations.\"\"\"\n",
    "    # Get all variables and metrics from the first elapsed forecast duration\n",
    "    variables = metrics_by_leadtime[elapsed_forecast_durations[0]].index\n",
    "    metrics = metrics_by_leadtime[elapsed_forecast_durations[0]].columns\n",
    "\n",
    "    # Create subplots for each metric and variable combination\n",
    "    plotted_metrics = set()  # Track which metrics have been plotted\n",
    "\n",
    "    for metric in metrics:\n",
    "        if metric.endswith(\"ML\") or metric.endswith(\"NWP\"):\n",
    "            base_metric = metric.rsplit(\" \", 1)[0]  # Remove ML/NWP suffix\n",
    "\n",
    "            # Skip if we've already plotted this base metric\n",
    "            if base_metric in plotted_metrics:\n",
    "                continue\n",
    "            plotted_metrics.add(base_metric)\n",
    "\n",
    "            for var in variables:\n",
    "                fig, ax = plt.subplots(figsize=(12, 6), dpi=DPI)\n",
    "\n",
    "                # Get metric values for all elapsed forecast durations for ML\n",
    "                ml_values = [\n",
    "                    metrics_by_leadtime[efd].loc[var, f\"{base_metric} ML\"]\n",
    "                    for efd in elapsed_forecast_durations\n",
    "                ]\n",
    "                ax.plot(\n",
    "                    elapsed_forecast_durations,\n",
    "                    ml_values,\n",
    "                    color=COLORS[\"ml\"],\n",
    "                    linestyle=LINE_STYLES[\"ml\"][0],\n",
    "                    marker=LINE_STYLES[\"ml\"][1],\n",
    "                    label=\"ML\",\n",
    "                )\n",
    "\n",
    "                # Plot NWP if available\n",
    "                if f\"{base_metric} NWP\" in metrics:\n",
    "                    nwp_values = [\n",
    "                        metrics_by_leadtime[efd].loc[var, f\"{base_metric} NWP\"]\n",
    "                        for efd in elapsed_forecast_durations\n",
    "                    ]\n",
    "                    ax.plot(\n",
    "                        elapsed_forecast_durations,\n",
    "                        nwp_values,\n",
    "                        color=COLORS[\"nwp\"],\n",
    "                        linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "                        marker=LINE_STYLES[\"nwp\"][1],\n",
    "                        label=\"NWP\",\n",
    "                    )\n",
    "\n",
    "                ax.set_title(\n",
    "                    f\"{base_metric} Over Elapsed Forecast Durations for {var}\"\n",
    "                )\n",
    "                ax.set_xlabel(\"Elapsed Forecast Duration\")\n",
    "                units = VARIABLE_UNITS.get(var, \"\")\n",
    "                ax.set_ylabel(f\"{base_metric} [{units}]\")\n",
    "                ax.grid(True)\n",
    "                ax.legend()\n",
    "                plt.tight_layout()\n",
    "                save_plot(fig, f\"leadtime_{base_metric}_{var}\")\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "# Calculate metrics for all elapsed forecast durations\n",
    "with LocalCluster(\n",
    "    n_workers=16, threads_per_worker=1, memory_limit=\"32GB\"\n",
    ") as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        print(f\"Dask dashboard available at: {client.dashboard_link}\")\n",
    "\n",
    "        # For NWP variables\n",
    "        metrics_by_leadtime_nwp = calculate_metrics_over_leadtimes(\n",
    "            ds_gt,\n",
    "            ds_nwp,\n",
    "            ds_ml,\n",
    "            ds_ml.elapsed_forecast_duration.values,\n",
    "            list(VARIABLES_NWP.values()),\n",
    "            metrics_to_compute=[\"RMSE\", \"FSS\"],\n",
    "        )\n",
    "\n",
    "        # # For ML-only variables\n",
    "        # ml_only_vars = [\n",
    "        #     var\n",
    "        #     for var in VARIABLES_ML.values()\n",
    "        #     if var not in VARIABLES_NWP.values()\n",
    "        # ]\n",
    "        # metrics_by_leadtime_ml = calculate_metrics_over_leadtimes(\n",
    "        #     ds_gt,\n",
    "        #     None,\n",
    "        #     ds_ml,\n",
    "        #     ds_ml.elapsed_forecast_duration.values,\n",
    "        #     ml_only_vars,\n",
    "        #     metrics_to_compute=[\"RMSE\", \"FSS\"],\n",
    "        # )\n",
    "\n",
    "# Plot metrics evolution over elapsed forecast durations\n",
    "print(\"\\nPlotting metrics for NWP variables:\")\n",
    "plot_metrics_over_leadtimes(\n",
    "    metrics_by_leadtime_nwp, ds_ml.elapsed_forecast_duration.values\n",
    ")\n",
    "\n",
    "# print(\"\\nPlotting metrics for ML-only variables:\")\n",
    "# plot_metrics_over_leadtimes(\n",
    "#     metrics_by_leadtime_ml, ds_ml.elapsed_forecast_duration.values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_meteoswiss_metrics_over_leadtimes(\n",
    "    ds_gt, ds_ml, ds_nwp, elapsed_forecast_durations\n",
    "):\n",
    "    \"\"\"Calculate MeteoSwiss verification metrics for each elapsed forecast duration.\n",
    "\n",
    "    Args:\n",
    "        ds_gt: Ground truth dataset\n",
    "        ds_ml: ML model predictions\n",
    "        ds_nwp: NWP predictions (optional)\n",
    "        elapsed_forecast_durations: Array of forecast durations\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing metrics for each lead time\n",
    "    \"\"\"\n",
    "    metrics_by_leadtime = {}\n",
    "\n",
    "    for efd in elapsed_forecast_durations:\n",
    "        metrics_by_leadtime[efd] = {}\n",
    "\n",
    "        # Select data for current lead time\n",
    "        ds_ml_lead = ds_ml.sel(elapsed_forecast_duration=efd)\n",
    "        ds_nwp_lead = (\n",
    "            ds_nwp.sel(elapsed_forecast_duration=efd)\n",
    "            if ds_nwp is not None\n",
    "            else None\n",
    "        )\n",
    "        ds_gt_lead = ds_gt.sel(time=ds_ml_lead.forecast_time)\n",
    "\n",
    "        # --- Group 1: Precipitation Metrics ---\n",
    "        if \"precipitation\" in ds_gt_lead:\n",
    "            metrics_by_leadtime[efd][\"precipitation\"] = {}\n",
    "            y_true = ds_gt_lead[\"precipitation\"].values\n",
    "            y_ml = ds_ml_lead[\"precipitation\"].values\n",
    "            y_nwp = (\n",
    "                ds_nwp_lead[\"precipitation\"].values\n",
    "                if ds_nwp_lead is not None\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            for thr in precip_thresholds:\n",
    "                metrics_by_leadtime[efd][\"precipitation\"][f\"{thr}mm/h\"] = {\n",
    "                    \"ML\": {\n",
    "                        \"MAE\": mean_absolute_error(y_true, y_ml),\n",
    "                        \"FBI\": frequency_bias(y_true, y_ml, thr),\n",
    "                        \"ETS\": ets_for_threshold(y_true, y_ml, thr),\n",
    "                    }\n",
    "                }\n",
    "                if y_nwp is not None:\n",
    "                    metrics_by_leadtime[efd][\"precipitation\"][f\"{thr}mm/h\"][\n",
    "                        \"NWP\"\n",
    "                    ] = {\n",
    "                        \"MAE\": mean_absolute_error(y_true, y_nwp),\n",
    "                        \"FBI\": frequency_bias(y_true, y_nwp, thr),\n",
    "                        \"ETS\": ets_for_threshold(y_true, y_nwp, thr),\n",
    "                    }\n",
    "\n",
    "        # --- Group 2: Wind Metrics ---\n",
    "        if \"wind_u_10m\" in ds_gt_lead and \"wind_v_10m\" in ds_gt_lead:\n",
    "            metrics_by_leadtime[efd][\"wind\"] = {}\n",
    "            for var in [\"wind_u_10m\", \"wind_v_10m\"]:\n",
    "                metrics_by_leadtime[efd][\"wind\"][var] = {}\n",
    "                y_true = ds_gt_lead[var].values\n",
    "                y_ml = ds_ml_lead[var].values\n",
    "                y_nwp = (\n",
    "                    ds_nwp_lead[var].values if ds_nwp_lead is not None else None\n",
    "                )\n",
    "\n",
    "                for thr in wind_thresholds:\n",
    "                    metrics_by_leadtime[efd][\"wind\"][var][f\"{thr}m/s\"] = {\n",
    "                        \"ML\": {\n",
    "                            \"MAE\": mean_absolute_error(y_true, y_ml),\n",
    "                            \"FBI\": frequency_bias(y_true, y_ml, thr),\n",
    "                            \"ETS\": ets_for_threshold(y_true, y_ml, thr),\n",
    "                        }\n",
    "                    }\n",
    "                    if y_nwp is not None:\n",
    "                        metrics_by_leadtime[efd][\"wind\"][var][f\"{thr}m/s\"][\n",
    "                            \"NWP\"\n",
    "                        ] = {\n",
    "                            \"MAE\": mean_absolute_error(y_true, y_nwp),\n",
    "                            \"FBI\": frequency_bias(y_true, y_nwp, thr),\n",
    "                            \"ETS\": ets_for_threshold(y_true, y_nwp, thr),\n",
    "                        }\n",
    "\n",
    "        # --- Group 3: Radiation and Temperature Metrics (ML only) ---\n",
    "        metrics_by_leadtime[efd][\"radiation_temp\"] = {}\n",
    "        for var in vars_stdev:\n",
    "            if var in ds_gt_lead and var in ds_ml_lead:\n",
    "                y_true = ds_gt_lead[var].values\n",
    "                y_ml = ds_ml_lead[var].values\n",
    "\n",
    "                metrics_by_leadtime[efd][\"radiation_temp\"][var] = {\n",
    "                    \"ML\": {\n",
    "                        \"MAE\": mean_absolute_error(y_true, y_ml),\n",
    "                        \"STDEV\": stdev_error(y_true, y_ml),\n",
    "                    }\n",
    "                }\n",
    "\n",
    "    return metrics_by_leadtime\n",
    "\n",
    "\n",
    "def plot_meteoswiss_verification_metrics_over_leadtimes(\n",
    "    metrics_by_leadtime, elapsed_forecast_durations\n",
    "):\n",
    "    \"\"\"Create separate line plots for MeteoSwiss verification metrics over lead times.\n",
    "\n",
    "    Args:\n",
    "        metrics_by_leadtime: Dictionary containing metrics for each lead time\n",
    "        elapsed_forecast_durations: Array of forecast durations in hours\n",
    "    \"\"\"\n",
    "    # Plot precipitation metrics if data exists\n",
    "    if \"precipitation\" in metrics_by_leadtime[elapsed_forecast_durations[0]]:\n",
    "        for metric in [\"MAE\", \"FBI\", \"ETS\"]:\n",
    "            fig = plt.figure(figsize=(10, 6))\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "            for thr in precip_thresholds:\n",
    "                # Plot ML metrics\n",
    "                ml_values = [\n",
    "                    metrics_by_leadtime[efd][\"precipitation\"][f\"{thr}mm/h\"][\n",
    "                        \"ML\"\n",
    "                    ][metric]\n",
    "                    for efd in elapsed_forecast_durations\n",
    "                ]\n",
    "                ax.plot(\n",
    "                    elapsed_forecast_durations,\n",
    "                    ml_values,\n",
    "                    linestyle=LINE_STYLES[\"ml\"][0],\n",
    "                    marker=LINE_STYLES[\"ml\"][1],\n",
    "                    label=f\"ML {thr}mm/h\",\n",
    "                )\n",
    "\n",
    "                # Check if NWP data exists for this threshold\n",
    "                if (\n",
    "                    f\"{thr}mm/h\"\n",
    "                    in metrics_by_leadtime[elapsed_forecast_durations[0]][\n",
    "                        \"precipitation\"\n",
    "                    ]\n",
    "                    and \"NWP\"\n",
    "                    in metrics_by_leadtime[elapsed_forecast_durations[0]][\n",
    "                        \"precipitation\"\n",
    "                    ][f\"{thr}mm/h\"]\n",
    "                ):\n",
    "                    nwp_values = [\n",
    "                        metrics_by_leadtime[efd][\"precipitation\"][f\"{thr}mm/h\"][\n",
    "                            \"NWP\"\n",
    "                        ][metric]\n",
    "                        for efd in elapsed_forecast_durations\n",
    "                    ]\n",
    "                    ax.plot(\n",
    "                        elapsed_forecast_durations,\n",
    "                        nwp_values,\n",
    "                        linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "                        marker=LINE_STYLES[\"nwp\"][1],\n",
    "                        label=f\"NWP {thr}mm/h\",\n",
    "                    )\n",
    "\n",
    "            ax.set_title(f\"Precipitation {metric}\")\n",
    "            ax.set_xlabel(\"Elapsed Forecast Duration [h]\")\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "            save_plot(fig, f\"leadtime_precip_{metric}\")\n",
    "            plt.show()\n",
    "\n",
    "    # Plot wind metrics if data exists\n",
    "    if \"wind\" in metrics_by_leadtime[elapsed_forecast_durations[0]]:\n",
    "        for var in [\"wind_u_10m\", \"wind_v_10m\"]:\n",
    "            if (\n",
    "                var\n",
    "                in metrics_by_leadtime[elapsed_forecast_durations[0]][\"wind\"]\n",
    "            ):\n",
    "                for metric in [\"MAE\", \"FBI\", \"ETS\"]:\n",
    "                    fig = plt.figure(figsize=(10, 6))\n",
    "                    ax = fig.add_subplot(111)\n",
    "\n",
    "                    for thr in wind_thresholds:\n",
    "                        # Plot ML metrics\n",
    "                        ml_values = [\n",
    "                            metrics_by_leadtime[efd][\"wind\"][var][f\"{thr}m/s\"][\n",
    "                                \"ML\"\n",
    "                            ][metric]\n",
    "                            for efd in elapsed_forecast_durations\n",
    "                        ]\n",
    "                        ax.plot(\n",
    "                            elapsed_forecast_durations,\n",
    "                            ml_values,\n",
    "                            linestyle=LINE_STYLES[\"ml\"][0],\n",
    "                            marker=LINE_STYLES[\"ml\"][1],\n",
    "                            label=f\"ML {thr}m/s\",\n",
    "                        )\n",
    "\n",
    "                        # Check if NWP data exists for this threshold\n",
    "                        if (\n",
    "                            f\"{thr}m/s\"\n",
    "                            in metrics_by_leadtime[\n",
    "                                elapsed_forecast_durations[0]\n",
    "                            ][\"wind\"][var]\n",
    "                            and \"NWP\"\n",
    "                            in metrics_by_leadtime[\n",
    "                                elapsed_forecast_durations[0]\n",
    "                            ][\"wind\"][var][f\"{thr}m/s\"]\n",
    "                        ):\n",
    "                            nwp_values = [\n",
    "                                metrics_by_leadtime[efd][\"wind\"][var][\n",
    "                                    f\"{thr}m/s\"\n",
    "                                ][\"NWP\"][metric]\n",
    "                                for efd in elapsed_forecast_durations\n",
    "                            ]\n",
    "                            ax.plot(\n",
    "                                elapsed_forecast_durations,\n",
    "                                nwp_values,\n",
    "                                linestyle=LINE_STYLES[\"nwp\"][0],\n",
    "                                marker=LINE_STYLES[\"nwp\"][1],\n",
    "                                label=f\"NWP {thr}m/s\",\n",
    "                            )\n",
    "\n",
    "                    ax.set_title(f\"{var} {metric}\")\n",
    "                    ax.set_xlabel(\"Elapsed Forecast Duration [h]\")\n",
    "                    ax.set_ylabel(metric)\n",
    "                    ax.grid(True)\n",
    "                    ax.legend()\n",
    "                    plt.tight_layout()\n",
    "                    save_plot(fig, f\"leadtime_wind_{var}_{metric}\")\n",
    "                    plt.show()\n",
    "\n",
    "    # Plot radiation and temperature metrics (ML only) if data exists\n",
    "    if \"radiation_temp\" in metrics_by_leadtime[elapsed_forecast_durations[0]]:\n",
    "        for var in vars_stdev:\n",
    "            if (\n",
    "                var\n",
    "                in metrics_by_leadtime[elapsed_forecast_durations[0]][\n",
    "                    \"radiation_temp\"\n",
    "                ]\n",
    "            ):\n",
    "                for metric in [\"MAE\", \"STDEV\"]:\n",
    "                    fig = plt.figure(figsize=(10, 6))\n",
    "                    ax = fig.add_subplot(111)\n",
    "\n",
    "                    # Plot ML metrics only\n",
    "                    ml_values = [\n",
    "                        metrics_by_leadtime[efd][\"radiation_temp\"][var][\"ML\"][\n",
    "                            metric\n",
    "                        ]\n",
    "                        for efd in elapsed_forecast_durations\n",
    "                    ]\n",
    "                    ax.plot(\n",
    "                        elapsed_forecast_durations,\n",
    "                        ml_values,\n",
    "                        linestyle=LINE_STYLES[\"ml\"][0],\n",
    "                        marker=LINE_STYLES[\"ml\"][1],\n",
    "                        label=\"ML\",\n",
    "                    )\n",
    "\n",
    "                    ax.set_title(f\"{var} {metric}\")\n",
    "                    ax.set_xlabel(\"Elapsed Forecast Duration [h]\")\n",
    "                    ax.set_ylabel(f\"{metric} [{VARIABLE_UNITS.get(var, '')}]\")\n",
    "                    ax.grid(True)\n",
    "                    ax.legend()\n",
    "                    plt.tight_layout()\n",
    "                    save_plot(fig, f\"leadtime_{var}_{metric}\")\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "# Calculate MeteoSwiss metrics over lead times\n",
    "meteoswiss_metrics = calculate_meteoswiss_metrics_over_leadtimes(\n",
    "    ds_gt, ds_ml, ds_nwp, ds_ml.elapsed_forecast_duration.values\n",
    ")\n",
    "\n",
    "# Plot the metrics\n",
    "plot_meteoswiss_verification_metrics_over_leadtimes(\n",
    "    meteoswiss_metrics, ds_ml.elapsed_forecast_duration.values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a700aa6",
   "metadata": {},
   "source": [
    "The following two cells are only run for the first variable. Because otherwise if the user is not careful it will take a long time to run. To remove this limitation, simply remove the list() and [0] from the variable names in the plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_TIME is None:\n",
    "    time_selected = None\n",
    "else:\n",
    "    time_selected = ds_ml.sel(start_time=pd.to_datetime(PLOT_TIME)).start_time\n",
    "\n",
    "# 4. elapsed forecast duration plots for specific variable\n",
    "for elapsed_forecast_duration in ds_ml.elapsed_forecast_duration:\n",
    "    create_comparison_maps(\n",
    "        ds_gt=ds_gt,\n",
    "        ds_ml=ds_ml,\n",
    "        ds_nwp=ds_nwp,\n",
    "        ds_boundary=ds_boundary,\n",
    "        plot_time=time_selected,\n",
    "        elapsed_forecast_duration=elapsed_forecast_duration,\n",
    "        # SELECT VARIABLE HERE\n",
    "        var=list(VARIABLES_GROUND_TRUTH.values())[0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_TIME is None:\n",
    "    time_selected = None\n",
    "else:\n",
    "    time_selected = ds_ml.sel(start_time=pd.to_datetime(PLOT_TIME)).start_time\n",
    "\n",
    "# 4. elapsed forecast duration plots for specific variable\n",
    "for elapsed_forecast_duration in ds_ml.elapsed_forecast_duration:\n",
    "    create_error_maps(\n",
    "        ds_gt=ds_gt,\n",
    "        ds_ml=ds_ml,\n",
    "        ds_nwp=ds_nwp,\n",
    "        plot_time=time_selected,\n",
    "        elapsed_forecast_duration=elapsed_forecast_duration,\n",
    "        # SELECT VARIABLE HERE\n",
    "        var=list(VARIABLES_GROUND_TRUTH.values())[0],\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "neural-lam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
